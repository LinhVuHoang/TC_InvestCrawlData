[2023-09-25T13:47:13.708+0700] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:47:13.712+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:47:13.718+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:47:13.718+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:47:14.317+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:47:14.349+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:47:14.349+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:47:14.364+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:47:14.363+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:47:14.376+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.672 seconds
[2023-09-25T13:47:45.247+0700] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:47:45.248+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:47:45.250+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:47:45.249+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:47:45.459+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:47:45.483+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:47:45.483+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:47:45.501+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:47:45.500+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:47:45.513+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T13:48:15.592+0700] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:48:15.593+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:48:15.595+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:48:15.595+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:48:15.791+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:48:15.806+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:48:15.806+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:48:15.821+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:48:15.820+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:48:15.832+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T13:48:46.053+0700] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:48:46.054+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:48:46.056+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:48:46.056+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:48:46.253+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:48:46.268+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:48:46.268+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:48:46.281+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:48:46.281+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:48:46.293+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T13:49:16.368+0700] {processor.py:157} INFO - Started process (PID=253) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:49:16.370+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:49:16.374+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:49:16.374+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:49:16.584+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:49:16.601+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:49:16.600+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:49:16.614+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:49:16.614+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:49:16.624+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.262 seconds
[2023-09-25T13:49:46.767+0700] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:49:46.769+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:49:46.772+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:49:46.771+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:49:46.974+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:49:46.989+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:49:46.989+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:49:47.003+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:49:47.003+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:49:47.013+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T13:50:00.785+0700] {processor.py:157} INFO - Started process (PID=357) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:00.786+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:50:00.789+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:00.788+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:00.997+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:01.014+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:01.013+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:50:01.028+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:01.028+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:50:01.043+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.261 seconds
[2023-09-25T13:50:09.031+0700] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:09.032+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:50:09.034+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:09.034+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:09.238+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:09.256+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:09.256+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:50:09.272+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:09.272+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:50:09.289+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.262 seconds
[2023-09-25T13:50:14.154+0700] {processor.py:157} INFO - Started process (PID=368) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:14.155+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:50:14.157+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:14.157+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:14.360+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:14.377+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:14.376+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:50:14.391+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:14.390+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:50:14.403+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T13:50:44.463+0700] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:44.465+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:50:44.468+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:44.467+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:44.656+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:50:44.672+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:44.672+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:50:44.685+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:50:44.685+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:50:44.696+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.237 seconds
[2023-09-25T13:51:14.801+0700] {processor.py:157} INFO - Started process (PID=479) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:51:14.803+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:51:14.806+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:51:14.805+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:51:14.990+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:51:15.004+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:51:15.004+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:51:15.016+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:51:15.016+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:51:15.026+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.230 seconds
[2023-09-25T13:51:45.079+0700] {processor.py:157} INFO - Started process (PID=535) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:51:45.081+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:51:45.083+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:51:45.082+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:51:45.262+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:51:45.277+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:51:45.277+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:51:45.289+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:51:45.289+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:51:45.299+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.222 seconds
[2023-09-25T13:52:15.511+0700] {processor.py:157} INFO - Started process (PID=590) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:52:15.513+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:52:15.514+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:52:15.514+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:52:15.708+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:52:15.726+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:52:15.725+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:52:15.739+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:52:15.739+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:52:15.750+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.241 seconds
[2023-09-25T13:52:45.844+0700] {processor.py:157} INFO - Started process (PID=646) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:52:45.845+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:52:45.847+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:52:45.847+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:52:46.043+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:52:46.058+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:52:46.058+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:52:46.072+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:52:46.072+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:52:46.081+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T13:53:16.576+0700] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:53:16.578+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:53:16.581+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:53:16.580+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:53:16.777+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:53:16.793+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:53:16.793+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:53:16.806+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:53:16.806+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:53:16.817+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T13:53:47.180+0700] {processor.py:157} INFO - Started process (PID=757) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:53:47.182+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:53:47.186+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:53:47.185+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:53:47.380+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:53:47.395+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:53:47.395+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:53:47.409+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:53:47.408+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:53:47.420+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T13:54:17.579+0700] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:54:17.580+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:54:17.582+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:54:17.582+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:54:17.776+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:54:17.793+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:54:17.793+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:54:17.808+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:54:17.808+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:54:17.819+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T13:54:47.970+0700] {processor.py:157} INFO - Started process (PID=869) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:54:47.971+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:54:47.973+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:54:47.972+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:54:48.170+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:54:48.187+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:54:48.187+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:54:48.201+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:54:48.201+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:54:48.212+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T13:55:18.375+0700] {processor.py:157} INFO - Started process (PID=925) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:18.376+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:55:18.378+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:18.378+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:18.578+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:18.594+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:18.594+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:55:18.608+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:18.608+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:55:18.619+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T13:55:21.653+0700] {processor.py:157} INFO - Started process (PID=929) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:21.655+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:55:21.657+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:21.657+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:21.868+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:21.886+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:21.886+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:55:21.901+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:21.901+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:55:21.917+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T13:55:52.229+0700] {processor.py:157} INFO - Started process (PID=985) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:52.230+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:55:52.232+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:52.232+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:52.431+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:55:52.447+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:52.447+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:55:52.460+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:55:52.460+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:55:52.471+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T13:56:22.701+0700] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:56:22.702+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:56:22.705+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:56:22.705+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:56:22.909+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:56:22.924+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:56:22.924+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:56:22.938+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:56:22.937+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:56:22.948+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T13:56:53.191+0700] {processor.py:157} INFO - Started process (PID=1098) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:56:53.192+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:56:53.196+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:56:53.195+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:56:53.400+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:56:53.415+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:56:53.415+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:56:53.428+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:56:53.428+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:56:53.438+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T13:57:23.654+0700] {processor.py:157} INFO - Started process (PID=1154) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:57:23.656+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:57:23.658+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:57:23.658+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:57:23.891+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:57:23.911+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:57:23.911+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:57:23.928+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:57:23.927+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:57:23.943+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.291 seconds
[2023-09-25T13:57:54.236+0700] {processor.py:157} INFO - Started process (PID=1210) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:57:54.237+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:57:54.240+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:57:54.240+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:57:54.439+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:57:54.456+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:57:54.455+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:57:54.468+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:57:54.468+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:57:54.480+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.248 seconds
[2023-09-25T13:58:24.769+0700] {processor.py:157} INFO - Started process (PID=1266) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:58:24.770+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:58:24.772+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:58:24.772+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:58:24.976+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:58:24.991+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:58:24.991+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:58:25.004+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:58:25.004+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:58:25.016+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T13:58:55.199+0700] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:58:55.200+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:58:55.203+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:58:55.202+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:58:55.409+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:58:55.426+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:58:55.426+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:58:55.441+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:58:55.441+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:58:55.454+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.257 seconds
[2023-09-25T13:59:25.638+0700] {processor.py:157} INFO - Started process (PID=1378) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:59:25.640+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:59:25.642+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:59:25.642+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:59:25.851+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:59:25.867+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:59:25.866+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:59:25.880+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:59:25.880+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:59:25.893+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.259 seconds
[2023-09-25T13:59:56.100+0700] {processor.py:157} INFO - Started process (PID=1434) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:59:56.101+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T13:59:56.103+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:59:56.103+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:59:56.311+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T13:59:56.327+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:59:56.327+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T13:59:56.341+0700] {logging_mixin.py:151} INFO - [2023-09-25T13:59:56.340+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T13:59:56.352+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T14:00:26.508+0700] {processor.py:157} INFO - Started process (PID=1490) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:00:26.510+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:00:26.512+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:00:26.511+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:00:26.701+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:00:26.717+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:00:26.717+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:00:26.730+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:00:26.730+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:00:26.741+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.235 seconds
[2023-09-25T14:00:56.831+0700] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:00:56.832+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:00:56.835+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:00:56.835+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:00:57.042+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:00:57.059+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:00:57.058+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:00:57.072+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:00:57.072+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:00:57.083+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.257 seconds
[2023-09-25T14:01:27.238+0700] {processor.py:157} INFO - Started process (PID=1602) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:01:27.239+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:01:27.242+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:01:27.241+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:01:27.436+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:01:27.452+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:01:27.451+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:01:27.466+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:01:27.465+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:01:27.478+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T14:01:57.677+0700] {processor.py:157} INFO - Started process (PID=1658) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:01:57.679+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:01:57.682+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:01:57.681+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:01:57.874+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:01:57.890+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:01:57.889+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:01:57.902+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:01:57.902+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:01:57.913+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.240 seconds
[2023-09-25T14:03:20.503+0700] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:03:20.504+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:03:20.506+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:20.506+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:03:21.213+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:03:21.336+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:21.335+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T14:03:21.337+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:21.337+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:03:21.353+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:21.353+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:03:21.366+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.866 seconds
[2023-09-25T14:03:51.469+0700] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:03:51.470+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:03:51.472+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:51.472+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:03:51.684+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:03:51.702+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:51.702+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:03:51.718+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:03:51.718+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:03:51.730+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.264 seconds
[2023-09-25T14:04:21.999+0700] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:04:22.000+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:04:22.002+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:04:22.002+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:04:22.229+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:04:22.247+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:04:22.247+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:04:22.261+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:04:22.261+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:04:22.274+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.279 seconds
[2023-09-25T14:04:52.512+0700] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:04:52.515+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:04:52.520+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:04:52.520+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:04:52.731+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:04:52.748+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:04:52.748+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:04:52.762+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:04:52.762+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:04:52.774+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T14:05:23.355+0700] {processor.py:157} INFO - Started process (PID=253) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:05:23.356+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:05:23.360+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:05:23.359+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:05:23.565+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:05:23.581+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:05:23.580+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:05:23.593+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:05:23.593+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:05:23.604+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T14:05:53.809+0700] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:05:53.810+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:05:53.813+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:05:53.812+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:05:54.021+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:05:54.039+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:05:54.039+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:05:54.052+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:05:54.052+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:05:54.063+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.259 seconds
[2023-09-25T14:06:24.212+0700] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:06:24.213+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:06:24.217+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:06:24.216+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:06:24.426+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:06:24.442+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:06:24.442+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:06:24.456+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:06:24.456+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:06:24.466+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.259 seconds
[2023-09-25T14:06:54.628+0700] {processor.py:157} INFO - Started process (PID=420) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:06:54.629+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:06:54.633+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:06:54.632+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:06:54.835+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:06:54.852+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:06:54.851+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:06:54.865+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:06:54.865+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:06:54.876+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T14:07:24.937+0700] {processor.py:157} INFO - Started process (PID=476) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:07:24.938+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:07:24.942+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:07:24.942+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:07:25.153+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:07:25.172+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:07:25.171+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:07:25.184+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:07:25.184+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:07:25.195+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.261 seconds
[2023-09-25T14:07:55.296+0700] {processor.py:157} INFO - Started process (PID=534) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:07:55.297+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:07:55.299+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:07:55.299+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:07:55.503+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:07:55.520+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:07:55.519+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:07:55.533+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:07:55.533+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:07:55.544+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T14:08:20.421+0700] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:08:20.423+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:08:20.425+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:08:20.425+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:08:20.640+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:08:20.657+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:08:20.657+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:08:20.672+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:08:20.672+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:08:20.686+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.268 seconds
[2023-09-25T14:08:51.125+0700] {processor.py:157} INFO - Started process (PID=643) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:08:51.127+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:08:51.131+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:08:51.130+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:08:51.335+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:08:51.352+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:08:51.351+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:08:51.365+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:08:51.364+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:08:51.377+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T14:09:21.595+0700] {processor.py:157} INFO - Started process (PID=699) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:09:21.596+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:09:21.598+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:09:21.598+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:09:21.812+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:09:21.829+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:09:21.829+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:09:21.843+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:09:21.843+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:09:21.856+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.264 seconds
[2023-09-25T14:35:35.528+0700] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:35:35.529+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:35:35.531+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:35:35.530+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:35:36.235+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:35:36.353+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:35:36.353+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T14:35:36.354+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:35:36.354+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:35:36.368+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:35:36.368+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:35:36.397+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.872 seconds
[2023-09-25T14:36:06.876+0700] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:36:06.877+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:36:06.879+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:36:06.879+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:36:07.099+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:36:07.116+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:36:07.116+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:36:07.130+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:36:07.130+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:36:07.141+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T14:36:37.217+0700] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:36:37.218+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:36:37.220+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:36:37.219+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:36:37.414+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:36:37.430+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:36:37.429+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:36:37.442+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:36:37.442+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:36:37.453+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.239 seconds
[2023-09-25T14:37:07.839+0700] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:37:07.841+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:37:07.843+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:37:07.843+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:37:08.050+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:37:08.075+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:37:08.074+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:37:08.088+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:37:08.088+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:37:08.101+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T14:37:38.329+0700] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:37:38.331+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:37:38.335+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:37:38.334+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:37:38.539+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:37:38.555+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:37:38.555+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:37:38.568+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:37:38.568+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:37:38.579+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T14:38:08.786+0700] {processor.py:157} INFO - Started process (PID=312) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:38:08.787+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:38:08.790+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:38:08.789+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:38:08.987+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:38:09.002+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:38:09.002+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:38:09.015+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:38:09.015+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:38:09.027+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T14:38:39.214+0700] {processor.py:157} INFO - Started process (PID=368) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:38:39.215+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:38:39.218+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:38:39.218+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:38:39.416+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:38:39.432+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:38:39.432+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:38:39.445+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:38:39.445+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:38:39.457+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.248 seconds
[2023-09-25T14:39:09.796+0700] {processor.py:157} INFO - Started process (PID=424) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:39:09.798+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:39:09.801+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:39:09.800+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:39:10.002+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:39:10.019+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:39:10.019+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:39:10.033+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:39:10.032+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:39:10.043+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T14:39:40.234+0700] {processor.py:157} INFO - Started process (PID=480) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:39:40.236+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:39:40.239+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:39:40.239+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:39:40.437+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:39:40.453+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:39:40.453+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:39:40.467+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:39:40.467+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:39:40.478+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.250 seconds
[2023-09-25T14:40:10.652+0700] {processor.py:157} INFO - Started process (PID=536) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:40:10.653+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:40:10.655+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:40:10.655+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:40:10.849+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:40:10.864+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:40:10.864+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:40:10.879+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:40:10.879+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:40:10.891+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T14:40:41.082+0700] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:40:41.083+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:40:41.086+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:40:41.086+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:40:41.288+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:40:41.305+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:40:41.304+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:40:41.319+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:40:41.319+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:40:41.330+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T14:41:11.647+0700] {processor.py:157} INFO - Started process (PID=648) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:41:11.648+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:41:11.650+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:41:11.650+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:41:11.847+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:41:11.863+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:41:11.863+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:41:11.878+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:41:11.878+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:41:11.889+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T14:41:42.158+0700] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:41:42.159+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:41:42.163+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:41:42.162+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:41:42.389+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:41:42.407+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:41:42.406+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:41:42.424+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:41:42.424+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:41:42.439+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.284 seconds
[2023-09-25T14:42:12.878+0700] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:42:12.879+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:42:12.882+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:42:12.881+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:42:13.120+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:42:13.136+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:42:13.135+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:42:13.150+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:42:13.150+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:42:13.162+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.287 seconds
[2023-09-25T14:42:43.792+0700] {processor.py:157} INFO - Started process (PID=815) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:42:43.794+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:42:43.797+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:42:43.797+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:42:44.010+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:42:44.026+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:42:44.026+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:42:44.040+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:42:44.040+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:42:44.053+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T14:43:14.472+0700] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:43:14.474+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:43:14.476+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:43:14.476+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:43:14.682+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:43:14.698+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:43:14.697+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:43:14.711+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:43:14.710+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:43:14.722+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T14:43:45.113+0700] {processor.py:157} INFO - Started process (PID=927) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:43:45.115+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:43:45.118+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:43:45.118+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:43:45.334+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:43:45.352+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:43:45.352+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:43:45.366+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:43:45.366+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:43:45.380+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.273 seconds
[2023-09-25T14:44:15.778+0700] {processor.py:157} INFO - Started process (PID=983) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:44:15.780+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:44:15.782+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:44:15.781+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:44:15.983+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:44:16.000+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:44:16.000+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:44:16.014+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:44:16.013+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:44:16.026+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.250 seconds
[2023-09-25T14:44:46.499+0700] {processor.py:157} INFO - Started process (PID=1039) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:44:46.500+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:44:46.503+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:44:46.503+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:44:46.720+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:44:46.738+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:44:46.738+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:44:46.753+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:44:46.753+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:44:46.766+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.271 seconds
[2023-09-25T14:45:17.094+0700] {processor.py:157} INFO - Started process (PID=1095) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:45:17.095+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:45:17.098+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:45:17.098+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:45:17.294+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:45:17.310+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:45:17.310+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:45:17.324+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:45:17.324+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:45:17.335+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T14:45:47.609+0700] {processor.py:157} INFO - Started process (PID=1151) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:45:47.611+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:45:47.615+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:45:47.614+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:45:47.827+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:45:47.845+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:45:47.845+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:45:47.859+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:45:47.858+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:45:47.873+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T14:46:18.162+0700] {processor.py:157} INFO - Started process (PID=1207) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:46:18.163+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:46:18.165+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:46:18.165+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:46:18.368+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:46:18.386+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:46:18.385+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:46:18.401+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:46:18.401+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:46:18.412+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T14:46:48.459+0700] {processor.py:157} INFO - Started process (PID=1262) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:46:48.460+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:46:48.462+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:46:48.462+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:46:48.676+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:46:48.703+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:46:48.703+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:46:48.717+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:46:48.717+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:46:48.730+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.274 seconds
[2023-09-25T14:47:19.186+0700] {processor.py:157} INFO - Started process (PID=1319) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:47:19.187+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:47:19.190+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:47:19.189+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:47:19.397+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:47:19.414+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:47:19.414+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:47:19.429+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:47:19.429+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:47:19.440+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.257 seconds
[2023-09-25T14:47:49.998+0700] {processor.py:157} INFO - Started process (PID=1376) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:47:50.000+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:47:50.002+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:47:50.002+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:47:50.204+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:47:50.220+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:47:50.220+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:47:50.234+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:47:50.234+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:47:50.245+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.250 seconds
[2023-09-25T14:48:20.553+0700] {processor.py:157} INFO - Started process (PID=1432) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:48:20.555+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:48:20.558+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:48:20.557+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:48:20.757+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:48:20.774+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:48:20.774+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:48:20.788+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:48:20.788+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:48:20.800+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T14:48:51.130+0700] {processor.py:157} INFO - Started process (PID=1489) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:48:51.131+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:48:51.135+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:48:51.134+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:48:51.334+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:48:51.351+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:48:51.350+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:48:51.364+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:48:51.364+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:48:51.376+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T14:49:21.531+0700] {processor.py:157} INFO - Started process (PID=1544) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:49:21.533+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:49:21.537+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:49:21.536+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:49:21.750+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:49:21.766+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:49:21.766+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:49:21.781+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:49:21.781+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:49:21.793+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T14:49:51.906+0700] {processor.py:157} INFO - Started process (PID=1600) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:49:51.908+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:49:51.911+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:49:51.911+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:49:52.121+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:49:52.138+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:49:52.138+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:49:52.152+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:49:52.152+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:49:52.165+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.263 seconds
[2023-09-25T14:50:22.325+0700] {processor.py:157} INFO - Started process (PID=1656) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:50:22.326+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:50:22.331+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:50:22.330+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:50:22.533+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:50:22.549+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:50:22.548+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:50:22.562+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:50:22.562+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:50:22.573+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T14:50:52.951+0700] {processor.py:157} INFO - Started process (PID=1712) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:50:52.952+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:50:52.956+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:50:52.955+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:50:53.160+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:50:53.177+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:50:53.177+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:50:53.191+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:50:53.191+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:50:53.201+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T14:51:23.481+0700] {processor.py:157} INFO - Started process (PID=1768) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:51:23.482+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:51:23.484+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:51:23.484+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:51:23.682+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:51:23.700+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:51:23.699+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:51:23.714+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:51:23.714+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:51:23.726+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.248 seconds
[2023-09-25T14:51:54.186+0700] {processor.py:157} INFO - Started process (PID=1824) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:51:54.187+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:51:54.189+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:51:54.189+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:51:54.393+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:51:54.409+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:51:54.409+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:51:54.521+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:51:54.521+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:51:54.533+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.350 seconds
[2023-09-25T14:52:24.858+0700] {processor.py:157} INFO - Started process (PID=1880) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:52:24.860+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:52:24.863+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:24.863+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:52:25.068+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:52:25.084+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:25.084+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:52:25.188+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:25.188+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:52:25.198+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.344 seconds
[2023-09-25T14:52:55.426+0700] {processor.py:157} INFO - Started process (PID=1935) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:52:55.428+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:52:55.430+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:55.430+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:52:55.639+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:52:55.786+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:55.786+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T14:52:55.787+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:55.787+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:52:55.799+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:52:55.799+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:52:55.810+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.388 seconds
[2023-09-25T14:53:25.882+0700] {processor.py:157} INFO - Started process (PID=1990) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:53:25.884+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:53:25.886+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:53:25.886+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:53:26.100+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:53:26.118+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:53:26.117+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:53:26.228+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:53:26.228+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:53:26.241+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.364 seconds
[2023-09-25T14:53:56.561+0700] {processor.py:157} INFO - Started process (PID=2046) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:53:56.563+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:53:56.566+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:53:56.565+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:53:56.764+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:53:56.780+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:53:56.780+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:53:56.793+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:53:56.793+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:53:56.895+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T14:54:13.078+0700] {processor.py:157} INFO - Started process (PID=2099) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:13.081+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:54:13.084+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:13.084+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:13.399+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:13.414+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:13.414+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:54:13.427+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:13.427+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:54:13.445+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.370 seconds
[2023-09-25T14:54:42.912+0700] {processor.py:157} INFO - Started process (PID=2155) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:42.913+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:54:42.915+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:42.915+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:43.202+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:43.219+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:43.218+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:54:43.232+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:43.232+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:54:43.248+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.340 seconds
[2023-09-25T14:54:58.508+0700] {processor.py:157} INFO - Started process (PID=2161) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:58.509+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:54:58.511+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:58.511+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:58.816+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:54:58.831+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:58.830+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:54:58.845+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:54:58.845+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:54:58.860+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.354 seconds
[2023-09-25T14:55:29.303+0700] {processor.py:157} INFO - Started process (PID=2218) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:55:29.305+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:55:29.309+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:55:29.308+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:55:29.607+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:55:29.621+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:55:29.621+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:55:29.635+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:55:29.635+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:55:29.645+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.347 seconds
[2023-09-25T14:56:00.413+0700] {processor.py:157} INFO - Started process (PID=2274) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:56:00.416+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:56:00.419+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:56:00.418+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:56:00.718+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:56:00.736+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:56:00.735+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:56:00.748+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:56:00.748+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:56:00.761+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.352 seconds
[2023-09-25T14:56:31.728+0700] {processor.py:157} INFO - Started process (PID=2336) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:56:31.730+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:56:31.733+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:56:31.733+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:56:32.024+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:56:32.039+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:56:32.039+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:56:32.051+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:56:32.051+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:56:32.061+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T14:57:02.261+0700] {processor.py:157} INFO - Started process (PID=2392) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:57:02.263+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:57:02.266+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:57:02.265+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:57:02.551+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:57:02.565+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:57:02.564+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:57:02.577+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:57:02.576+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:57:02.586+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.329 seconds
[2023-09-25T14:57:33.003+0700] {processor.py:157} INFO - Started process (PID=2448) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:57:33.004+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:57:33.007+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:57:33.007+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:57:33.298+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:57:33.313+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:57:33.313+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:57:33.326+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:57:33.326+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:57:33.337+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.339 seconds
[2023-09-25T14:58:03.757+0700] {processor.py:157} INFO - Started process (PID=2504) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:58:03.759+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:58:03.762+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:58:03.762+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:58:04.063+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:58:04.078+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:58:04.077+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:58:04.090+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:58:04.089+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:58:04.100+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.349 seconds
[2023-09-25T14:58:34.442+0700] {processor.py:157} INFO - Started process (PID=2560) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:58:34.444+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:58:34.447+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:58:34.447+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:58:34.741+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:58:34.756+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:58:34.755+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:58:34.768+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:58:34.768+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:58:34.778+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.341 seconds
[2023-09-25T14:59:04.943+0700] {processor.py:157} INFO - Started process (PID=2616) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:59:04.950+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:59:04.953+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:59:04.953+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:59:05.248+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:59:05.262+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:59:05.262+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:59:05.275+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:59:05.275+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:59:05.286+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.347 seconds
[2023-09-25T14:59:36.047+0700] {processor.py:157} INFO - Started process (PID=2672) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:59:36.049+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T14:59:36.052+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:59:36.051+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:59:36.340+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T14:59:36.353+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:59:36.353+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T14:59:36.367+0700] {logging_mixin.py:151} INFO - [2023-09-25T14:59:36.367+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T14:59:36.377+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.334 seconds
[2023-09-25T15:00:06.591+0700] {processor.py:157} INFO - Started process (PID=2728) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:00:06.593+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:00:06.596+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:00:06.596+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:00:06.889+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:00:06.903+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:00:06.902+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:00:06.916+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:00:06.916+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:00:06.928+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.340 seconds
[2023-09-25T15:00:37.192+0700] {processor.py:157} INFO - Started process (PID=2784) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:00:37.193+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:00:37.196+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:00:37.195+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:00:37.481+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:00:37.495+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:00:37.495+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:00:37.508+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:00:37.508+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:00:37.518+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.330 seconds
[2023-09-25T15:01:07.731+0700] {processor.py:157} INFO - Started process (PID=2841) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:01:07.733+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:01:07.743+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:01:07.742+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:01:08.033+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:01:08.047+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:01:08.047+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:01:08.060+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:01:08.060+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:01:08.070+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.345 seconds
[2023-09-25T15:01:38.456+0700] {processor.py:157} INFO - Started process (PID=2897) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:01:38.458+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:01:38.461+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:01:38.461+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:01:38.753+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:01:38.767+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:01:38.766+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:01:38.779+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:01:38.779+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:01:38.790+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T15:02:09.098+0700] {processor.py:157} INFO - Started process (PID=2953) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:02:09.100+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:02:09.103+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:02:09.103+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:02:09.391+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:02:09.405+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:02:09.405+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:02:09.419+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:02:09.419+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:02:09.430+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.336 seconds
[2023-09-25T15:02:39.770+0700] {processor.py:157} INFO - Started process (PID=3009) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:02:39.772+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:02:39.775+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:02:39.774+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:02:40.065+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:02:40.078+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:02:40.078+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:02:40.091+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:02:40.091+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:02:40.101+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.336 seconds
[2023-09-25T15:03:10.917+0700] {processor.py:157} INFO - Started process (PID=3065) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:03:10.918+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:03:10.920+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:03:10.919+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:03:11.205+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:03:11.219+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:03:11.219+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:03:11.232+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:03:11.232+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:03:11.242+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.329 seconds
[2023-09-25T15:03:41.611+0700] {processor.py:157} INFO - Started process (PID=3121) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:03:41.613+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:03:41.616+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:03:41.615+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:03:41.906+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:03:41.920+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:03:41.920+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:03:41.932+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:03:41.932+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:03:41.941+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.335 seconds
[2023-09-25T15:04:12.230+0700] {processor.py:157} INFO - Started process (PID=3177) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:04:12.232+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:04:12.235+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:04:12.235+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:04:12.524+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:04:12.540+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:04:12.539+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:04:12.552+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:04:12.552+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:04:12.563+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T15:04:42.806+0700] {processor.py:157} INFO - Started process (PID=3233) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:04:42.807+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:04:42.811+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:04:42.810+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:04:43.104+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:04:43.118+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:04:43.118+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:04:43.132+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:04:43.131+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:04:43.142+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.341 seconds
[2023-09-25T15:05:13.407+0700] {processor.py:157} INFO - Started process (PID=3290) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:05:13.408+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:05:13.410+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:05:13.410+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:05:13.714+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:05:13.731+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:05:13.730+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:05:13.744+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:05:13.744+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:05:13.757+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.353 seconds
[2023-09-25T15:05:44.087+0700] {processor.py:157} INFO - Started process (PID=3346) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:05:44.088+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:05:44.091+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:05:44.090+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:05:44.396+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:05:44.411+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:05:44.411+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:05:44.424+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:05:44.424+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:05:44.435+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.353 seconds
[2023-09-25T15:06:14.712+0700] {processor.py:157} INFO - Started process (PID=3402) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:06:14.715+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:06:14.718+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:06:14.717+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:06:15.011+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:06:15.025+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:06:15.025+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:06:15.038+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:06:15.038+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:06:15.048+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.340 seconds
[2023-09-25T15:06:45.806+0700] {processor.py:157} INFO - Started process (PID=3457) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:06:45.808+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:06:45.810+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:06:45.809+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:06:46.105+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:06:46.120+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:06:46.120+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:06:46.133+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:06:46.133+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:06:46.144+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.342 seconds
[2023-09-25T15:07:16.545+0700] {processor.py:157} INFO - Started process (PID=3513) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:07:16.547+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:07:16.549+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:07:16.548+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:07:16.845+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:07:16.860+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:07:16.860+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:07:16.874+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:07:16.874+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:07:16.890+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.347 seconds
[2023-09-25T15:07:47.834+0700] {processor.py:157} INFO - Started process (PID=3569) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:07:47.836+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:07:47.839+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:07:47.839+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:07:48.136+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:07:48.151+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:07:48.151+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:07:48.164+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:07:48.163+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:07:48.174+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.345 seconds
[2023-09-25T15:08:18.214+0700] {processor.py:157} INFO - Started process (PID=3626) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:08:18.215+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:08:18.218+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:08:18.218+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:08:18.529+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:08:18.544+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:08:18.544+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:08:18.557+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:08:18.557+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:08:18.568+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.358 seconds
[2023-09-25T15:08:49.348+0700] {processor.py:157} INFO - Started process (PID=3681) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:08:49.350+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:08:49.352+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:08:49.352+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:08:49.638+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:08:49.652+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:08:49.652+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:08:49.664+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:08:49.664+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:08:49.675+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.331 seconds
[2023-09-25T15:09:20.514+0700] {processor.py:157} INFO - Started process (PID=3738) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:09:20.516+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:09:20.519+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:09:20.518+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:09:20.815+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:09:20.831+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:09:20.831+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:09:20.845+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:09:20.845+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:09:20.856+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.347 seconds
[2023-09-25T15:09:51.832+0700] {processor.py:157} INFO - Started process (PID=3794) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:09:51.833+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:09:51.836+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:09:51.836+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:09:52.126+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:09:52.140+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:09:52.139+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:09:52.152+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:09:52.152+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:09:52.162+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.336 seconds
[2023-09-25T15:10:22.268+0700] {processor.py:157} INFO - Started process (PID=3850) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:10:22.269+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:10:22.273+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:10:22.272+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:10:22.570+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:10:22.584+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:10:22.584+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:10:22.598+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:10:22.598+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:10:22.609+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.346 seconds
[2023-09-25T15:10:52.833+0700] {processor.py:157} INFO - Started process (PID=3907) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:10:52.834+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:10:52.837+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:10:52.836+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:10:53.151+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:10:53.167+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:10:53.167+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:10:53.182+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:10:53.182+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:10:53.194+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.364 seconds
[2023-09-25T15:11:24.124+0700] {processor.py:157} INFO - Started process (PID=3963) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:11:24.127+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:11:24.130+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:11:24.129+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:11:24.424+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:11:24.438+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:11:24.438+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:11:24.450+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:11:24.450+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:11:24.461+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.342 seconds
[2023-09-25T15:11:55.419+0700] {processor.py:157} INFO - Started process (PID=4019) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:11:55.421+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:11:55.424+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:11:55.424+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:11:55.727+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:11:55.743+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:11:55.743+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:11:55.757+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:11:55.757+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:11:55.769+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.354 seconds
[2023-09-25T15:12:26.166+0700] {processor.py:157} INFO - Started process (PID=4075) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:12:26.167+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:12:26.169+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:12:26.169+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:12:26.467+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:12:26.483+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:12:26.483+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:12:26.496+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:12:26.495+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:12:26.507+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.344 seconds
[2023-09-25T15:13:15.255+0700] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:13:15.258+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:13:15.261+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:15.260+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:13:15.981+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:13:16.102+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:16.102+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T15:13:16.103+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:16.103+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:13:16.116+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:16.116+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:13:16.130+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.878 seconds
[2023-09-25T15:13:47.137+0700] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:13:47.139+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:13:47.142+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:47.141+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:13:47.338+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:13:47.353+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:47.353+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:13:47.368+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:13:47.368+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:13:47.379+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.247 seconds
[2023-09-25T15:14:17.762+0700] {processor.py:157} INFO - Started process (PID=146) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:14:17.764+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:14:17.767+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:14:17.766+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:14:17.968+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:14:17.984+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:14:17.984+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:14:17.998+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:14:17.998+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:14:18.008+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T15:14:48.233+0700] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:14:48.234+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:14:48.237+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:14:48.236+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:14:48.432+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:14:48.452+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:14:48.451+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:14:48.466+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:14:48.466+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:14:48.477+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.249 seconds
[2023-09-25T15:15:18.590+0700] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:15:18.592+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:15:18.595+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:15:18.594+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:15:18.793+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:15:18.812+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:15:18.811+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:15:18.825+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:15:18.825+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:15:18.838+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T15:15:49.040+0700] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:15:49.041+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:15:49.044+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:15:49.044+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:15:49.247+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:15:49.265+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:15:49.264+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:15:49.280+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:15:49.280+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:15:49.292+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T15:16:19.738+0700] {processor.py:157} INFO - Started process (PID=369) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:16:19.740+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:16:19.743+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:16:19.742+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:16:19.943+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:16:19.960+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:16:19.959+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:16:19.974+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:16:19.974+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:16:19.985+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T15:16:50.347+0700] {processor.py:157} INFO - Started process (PID=425) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:16:50.349+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:16:50.352+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:16:50.351+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:16:50.554+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:16:50.573+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:16:50.572+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:16:50.588+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:16:50.588+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:16:50.599+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.257 seconds
[2023-09-25T15:17:20.763+0700] {processor.py:157} INFO - Started process (PID=481) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:17:20.764+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:17:20.766+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:17:20.766+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:17:20.961+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:17:20.978+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:17:20.978+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:17:20.992+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:17:20.992+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:17:21.003+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T15:17:51.112+0700] {processor.py:157} INFO - Started process (PID=537) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:17:51.113+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:17:51.116+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:17:51.116+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:17:51.317+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:17:51.333+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:17:51.333+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:17:51.349+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:17:51.348+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:17:51.360+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T15:18:21.442+0700] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:18:21.444+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:18:21.446+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:18:21.446+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:18:21.656+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:18:21.674+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:18:21.674+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:18:21.690+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:18:21.689+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:18:21.702+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.263 seconds
[2023-09-25T15:18:51.862+0700] {processor.py:157} INFO - Started process (PID=648) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:18:51.863+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:18:51.865+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:18:51.865+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:18:52.077+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:18:52.094+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:18:52.094+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:18:52.111+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:18:52.111+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:18:52.126+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T15:19:22.528+0700] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:19:22.529+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:19:22.531+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:19:22.531+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:19:22.729+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:19:22.745+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:19:22.744+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:19:22.760+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:19:22.760+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:19:22.771+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T15:19:52.967+0700] {processor.py:157} INFO - Started process (PID=760) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:19:52.968+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:19:52.970+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:19:52.970+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:19:53.183+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:19:53.202+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:19:53.202+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:19:53.220+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:19:53.219+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:19:53.246+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.282 seconds
[2023-09-25T15:20:23.572+0700] {processor.py:157} INFO - Started process (PID=816) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:20:23.574+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:20:23.576+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:20:23.576+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:20:23.778+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:20:23.801+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:20:23.801+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:20:23.819+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:20:23.819+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:20:23.830+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.261 seconds
[2023-09-25T15:20:54.152+0700] {processor.py:157} INFO - Started process (PID=873) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:20:54.154+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:20:54.157+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:20:54.157+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:20:54.369+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:20:54.386+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:20:54.386+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:20:54.400+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:20:54.400+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:20:54.410+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.262 seconds
[2023-09-25T15:21:24.908+0700] {processor.py:157} INFO - Started process (PID=929) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:21:24.909+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:21:24.913+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:21:24.913+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:21:25.121+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:21:25.138+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:21:25.138+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:21:25.153+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:21:25.153+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:21:25.164+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.259 seconds
[2023-09-25T15:21:55.806+0700] {processor.py:157} INFO - Started process (PID=985) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:21:55.808+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:21:55.812+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:21:55.812+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:21:56.023+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:21:56.041+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:21:56.040+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:21:56.055+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:21:56.055+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:21:56.066+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.264 seconds
[2023-09-25T15:22:26.298+0700] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:22:26.300+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:22:26.303+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:22:26.302+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:22:26.510+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:22:26.532+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:22:26.532+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:22:26.548+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:22:26.547+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:22:26.559+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.266 seconds
[2023-09-25T15:22:56.776+0700] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:22:56.778+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:22:56.780+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:22:56.780+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:22:56.977+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:22:56.992+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:22:56.992+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:22:57.006+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:22:57.006+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:22:57.016+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T15:23:27.266+0700] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:23:27.268+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:23:27.275+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:23:27.275+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:23:27.487+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:23:27.504+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:23:27.504+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:23:27.519+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:23:27.519+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:23:27.532+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T15:23:57.715+0700] {processor.py:157} INFO - Started process (PID=1208) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:23:57.717+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:23:57.720+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:23:57.719+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:23:57.918+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:23:57.938+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:23:57.938+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:23:57.954+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:23:57.954+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:23:57.965+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T15:24:28.257+0700] {processor.py:157} INFO - Started process (PID=1264) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:24:28.258+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:24:28.260+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:24:28.260+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:24:28.466+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:24:28.484+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:24:28.484+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:24:28.497+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:24:28.497+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:24:28.510+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T15:24:58.806+0700] {processor.py:157} INFO - Started process (PID=1320) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:24:58.808+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:24:58.810+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:24:58.810+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:24:59.004+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:24:59.022+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:24:59.022+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:24:59.036+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:24:59.036+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:24:59.046+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T15:25:29.477+0700] {processor.py:157} INFO - Started process (PID=1376) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:25:29.478+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:25:29.481+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:25:29.481+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:25:29.676+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:25:29.693+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:25:29.692+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:25:29.706+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:25:29.706+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:25:29.718+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T15:25:59.967+0700] {processor.py:157} INFO - Started process (PID=1432) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:25:59.969+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:25:59.973+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:25:59.972+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:26:00.173+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:26:00.191+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:26:00.191+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:26:00.206+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:26:00.206+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:26:00.217+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T15:26:30.647+0700] {processor.py:157} INFO - Started process (PID=1488) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:26:30.649+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:26:30.652+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:26:30.651+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:26:30.861+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:26:30.880+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:26:30.880+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:26:30.897+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:26:30.896+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:26:30.912+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T15:27:01.234+0700] {processor.py:157} INFO - Started process (PID=1544) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:27:01.235+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:27:01.237+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:27:01.237+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:27:01.437+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:27:01.453+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:27:01.453+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:27:01.469+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:27:01.468+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:27:01.481+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.250 seconds
[2023-09-25T15:27:31.686+0700] {processor.py:157} INFO - Started process (PID=1600) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:27:31.687+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:27:31.692+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:27:31.691+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:27:31.884+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:27:31.902+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:27:31.902+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:27:32.016+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:27:32.016+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:27:32.031+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.347 seconds
[2023-09-25T15:28:02.168+0700] {processor.py:157} INFO - Started process (PID=1658) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:28:02.169+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:28:02.171+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:28:02.171+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:28:02.369+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:28:02.387+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:28:02.387+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:28:02.489+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:28:02.489+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:28:02.499+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.334 seconds
[2023-09-25T15:28:32.737+0700] {processor.py:157} INFO - Started process (PID=1712) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:28:32.739+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:28:32.742+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:28:32.741+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:28:32.936+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:28:32.953+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:28:32.953+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:28:32.967+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:28:32.967+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:28:32.978+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T15:29:03.070+0700] {processor.py:157} INFO - Started process (PID=1768) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:29:03.071+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:29:03.074+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:29:03.073+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:29:03.268+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:29:03.284+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:29:03.284+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:29:03.298+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:29:03.297+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:29:03.308+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T15:29:33.473+0700] {processor.py:157} INFO - Started process (PID=1824) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:29:33.475+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:29:33.477+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:29:33.477+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:29:33.672+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:29:33.688+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:29:33.688+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:29:33.701+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:29:33.701+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:29:33.712+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T15:30:03.920+0700] {processor.py:157} INFO - Started process (PID=1880) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:30:03.921+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:30:03.923+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:30:03.923+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:30:04.129+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:30:04.150+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:30:04.149+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:30:04.166+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:30:04.166+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:30:04.180+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.262 seconds
[2023-09-25T15:30:35.145+0700] {processor.py:157} INFO - Started process (PID=1936) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:30:35.147+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:30:35.149+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:30:35.149+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:30:35.349+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:30:35.368+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:30:35.367+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:30:35.474+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:30:35.474+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:30:35.484+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.343 seconds
[2023-09-25T15:31:05.835+0700] {processor.py:157} INFO - Started process (PID=1992) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:31:05.837+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:31:05.841+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:31:05.840+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:31:06.042+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:31:06.059+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:31:06.059+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:31:06.168+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:31:06.168+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:31:06.179+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.348 seconds
[2023-09-25T15:31:36.671+0700] {processor.py:157} INFO - Started process (PID=2048) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:31:36.672+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:31:36.674+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:31:36.674+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:31:36.869+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:31:36.886+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:31:36.885+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:31:37.010+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:31:37.010+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:31:37.021+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.352 seconds
[2023-09-25T15:32:07.336+0700] {processor.py:157} INFO - Started process (PID=2104) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:32:07.338+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:32:07.341+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:32:07.341+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:32:07.633+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:32:07.647+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:32:07.646+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:32:07.658+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:32:07.658+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:32:07.668+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.335 seconds
[2023-09-25T15:32:38.299+0700] {processor.py:157} INFO - Started process (PID=2159) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:32:38.301+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:32:38.305+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:32:38.304+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:32:38.597+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:32:38.611+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:32:38.610+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:32:38.623+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:32:38.623+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:32:38.633+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.340 seconds
[2023-09-25T15:33:08.802+0700] {processor.py:157} INFO - Started process (PID=2214) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:33:08.804+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:33:08.807+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:33:08.806+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:33:09.099+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:33:09.113+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:33:09.113+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:33:09.125+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:33:09.125+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:33:09.136+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.340 seconds
[2023-09-25T15:33:39.407+0700] {processor.py:157} INFO - Started process (PID=2269) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:33:39.409+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:33:39.412+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:33:39.411+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:33:39.619+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:33:39.728+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:33:39.728+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:33:39.742+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:33:39.742+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:33:39.754+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.351 seconds
[2023-09-25T15:34:09.946+0700] {processor.py:157} INFO - Started process (PID=2324) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:34:09.947+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:34:09.949+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:34:09.949+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:34:10.240+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:34:10.254+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:34:10.253+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:34:10.267+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:34:10.267+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:34:10.277+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.336 seconds
[2023-09-25T15:34:40.583+0700] {processor.py:157} INFO - Started process (PID=2387) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:34:40.585+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:34:40.587+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:34:40.587+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:34:40.879+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:34:40.893+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:34:40.893+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:34:40.907+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:34:40.907+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:34:40.917+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T15:35:11.137+0700] {processor.py:157} INFO - Started process (PID=2442) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:35:11.139+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:35:11.144+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:35:11.144+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:35:11.445+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:35:11.460+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:35:11.459+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:35:11.473+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:35:11.473+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:35:11.484+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.351 seconds
[2023-09-25T15:35:41.873+0700] {processor.py:157} INFO - Started process (PID=2498) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:35:41.874+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:35:41.876+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:35:41.876+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:35:42.167+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:35:42.181+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:35:42.181+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:35:42.194+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:35:42.194+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:35:42.205+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.337 seconds
[2023-09-25T15:36:12.621+0700] {processor.py:157} INFO - Started process (PID=2554) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:36:12.623+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:36:12.626+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:36:12.626+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:36:12.926+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:36:12.942+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:36:12.941+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:36:12.958+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:36:12.957+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:36:12.971+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.354 seconds
[2023-09-25T15:36:43.283+0700] {processor.py:157} INFO - Started process (PID=2610) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:36:43.285+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:36:43.287+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:36:43.287+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:36:43.586+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:36:43.601+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:36:43.600+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:36:43.613+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:36:43.613+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:36:43.624+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.344 seconds
[2023-09-25T15:37:13.867+0700] {processor.py:157} INFO - Started process (PID=2666) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:37:13.868+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:37:13.871+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:37:13.870+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:37:14.155+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:37:14.168+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:37:14.168+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:37:14.181+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:37:14.181+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:37:14.192+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.328 seconds
[2023-09-25T15:37:44.553+0700] {processor.py:157} INFO - Started process (PID=2722) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:37:44.555+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:37:44.558+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:37:44.558+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:37:44.854+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:37:44.874+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:37:44.874+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:37:44.886+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:37:44.886+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:37:44.897+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.349 seconds
[2023-09-25T15:38:15.132+0700] {processor.py:157} INFO - Started process (PID=2778) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:38:15.134+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:38:15.136+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:38:15.136+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:38:15.451+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:38:15.468+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:38:15.467+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:38:15.483+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:38:15.483+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:38:15.498+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.368 seconds
[2023-09-25T15:38:45.894+0700] {processor.py:157} INFO - Started process (PID=2833) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:38:45.896+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:38:45.898+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:38:45.898+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:38:46.233+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:38:46.249+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:38:46.249+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:38:46.263+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:38:46.263+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:38:46.274+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.384 seconds
[2023-09-25T15:39:17.147+0700] {processor.py:157} INFO - Started process (PID=2888) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:39:17.148+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:39:17.150+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:39:17.150+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:39:17.444+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:39:17.462+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:39:17.462+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:39:17.477+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:39:17.476+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:39:17.488+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.344 seconds
[2023-09-25T15:39:47.786+0700] {processor.py:157} INFO - Started process (PID=2944) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:39:47.787+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:39:47.789+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:39:47.789+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:39:48.072+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:39:48.086+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:39:48.086+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:39:48.099+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:39:48.099+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:39:48.109+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.325 seconds
[2023-09-25T15:40:18.532+0700] {processor.py:157} INFO - Started process (PID=3000) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:40:18.534+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:40:18.538+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:40:18.538+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:40:18.838+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:40:18.852+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:40:18.852+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:40:18.865+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:40:18.865+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:40:18.875+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.348 seconds
[2023-09-25T15:40:49.868+0700] {processor.py:157} INFO - Started process (PID=3056) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:40:49.870+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:40:49.872+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:40:49.872+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:40:50.175+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:40:50.190+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:40:50.190+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:40:50.204+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:40:50.204+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:40:50.215+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.350 seconds
[2023-09-25T15:41:21.056+0700] {processor.py:157} INFO - Started process (PID=3112) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:41:21.057+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:41:21.061+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:41:21.060+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:41:21.347+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:41:21.364+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:41:21.364+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:41:21.377+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:41:21.377+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:41:21.387+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.336 seconds
[2023-09-25T15:41:51.888+0700] {processor.py:157} INFO - Started process (PID=3168) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:41:51.890+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:41:51.893+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:41:51.892+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:41:52.170+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:41:52.184+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:41:52.184+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:41:52.196+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:41:52.196+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:41:52.206+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.322 seconds
[2023-09-25T15:42:22.735+0700] {processor.py:157} INFO - Started process (PID=3223) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:42:22.736+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:42:22.738+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:42:22.738+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:42:23.036+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:42:23.054+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:42:23.053+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:42:23.067+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:42:23.067+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:42:23.078+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.346 seconds
[2023-09-25T15:42:53.927+0700] {processor.py:157} INFO - Started process (PID=3279) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:42:53.928+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:42:53.930+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:42:53.930+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:42:54.222+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:42:54.237+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:42:54.236+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:42:54.250+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:42:54.250+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:42:54.262+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T15:43:24.612+0700] {processor.py:157} INFO - Started process (PID=3335) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:43:24.614+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:43:24.617+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:43:24.617+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:43:24.893+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:43:24.907+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:43:24.906+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:43:24.919+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:43:24.919+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:43:24.929+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.322 seconds
[2023-09-25T15:43:55.149+0700] {processor.py:157} INFO - Started process (PID=3390) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:43:55.150+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:43:55.153+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:43:55.153+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:43:55.434+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:43:55.448+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:43:55.448+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:43:55.461+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:43:55.461+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:43:55.472+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.328 seconds
[2023-09-25T15:44:25.537+0700] {processor.py:157} INFO - Started process (PID=3446) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:44:25.539+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:44:25.542+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:44:25.541+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:44:25.825+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:44:25.839+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:44:25.838+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:44:25.851+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:44:25.851+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:44:25.861+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.329 seconds
[2023-09-25T15:44:56.240+0700] {processor.py:157} INFO - Started process (PID=3503) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:44:56.242+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:44:56.245+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:44:56.244+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:44:56.519+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:44:56.533+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:44:56.533+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:44:56.546+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:44:56.545+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:44:56.556+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.320 seconds
[2023-09-25T15:45:26.882+0700] {processor.py:157} INFO - Started process (PID=3560) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:45:26.883+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:45:26.886+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:45:26.885+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:45:27.165+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:45:27.179+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:45:27.178+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:45:27.191+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:45:27.191+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:45:27.201+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.324 seconds
[2023-09-25T15:45:57.699+0700] {processor.py:157} INFO - Started process (PID=3616) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:45:57.701+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:45:57.703+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:45:57.703+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:45:58.006+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:45:58.022+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:45:58.021+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:45:58.034+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:45:58.034+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:45:58.045+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.351 seconds
[2023-09-25T15:46:28.312+0700] {processor.py:157} INFO - Started process (PID=3672) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:46:28.314+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:46:28.317+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:46:28.316+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:46:28.614+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:46:28.628+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:46:28.627+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:46:28.640+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:46:28.639+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:46:28.650+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.342 seconds
[2023-09-25T15:46:59.069+0700] {processor.py:157} INFO - Started process (PID=3728) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:46:59.071+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:46:59.074+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:46:59.073+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:46:59.350+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:46:59.364+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:46:59.364+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T15:46:59.376+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:46:59.376+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T15:46:59.385+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.321 seconds
[2023-09-25T15:47:08.373+0700] {processor.py:157} INFO - Started process (PID=3773) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:08.375+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:47:08.378+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:08.377+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:08.653+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:08.651+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:47:08.654+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:08.669+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.300 seconds
[2023-09-25T15:47:11.595+0700] {processor.py:157} INFO - Started process (PID=3775) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:11.596+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:47:11.598+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:11.597+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:11.877+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:11.875+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:47:11.878+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:11.891+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.299 seconds
[2023-09-25T15:47:24.145+0700] {processor.py:157} INFO - Started process (PID=3786) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:24.147+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:47:24.149+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:24.149+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:24.435+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:24.433+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:47:24.436+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:24.449+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.307 seconds
[2023-09-25T15:47:29.387+0700] {processor.py:157} INFO - Started process (PID=3790) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:29.389+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:47:29.392+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:29.391+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:29.695+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:47:29.693+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:47:29.696+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:47:29.711+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.327 seconds
[2023-09-25T15:48:00.095+0700] {processor.py:157} INFO - Started process (PID=3846) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:00.096+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:48:00.099+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:48:00.099+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:00.373+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:48:00.371+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:48:00.374+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:00.389+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.298 seconds
[2023-09-25T15:48:30.924+0700] {processor.py:157} INFO - Started process (PID=3902) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:30.925+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:48:30.928+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:48:30.928+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:31.211+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:48:31.209+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:48:31.211+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:31.224+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.306 seconds
[2023-09-25T15:48:46.477+0700] {processor.py:157} INFO - Started process (PID=3956) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:46.478+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:48:46.479+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:48:46.479+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:46.485+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:48:46.484+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 167
    python_callable=run_my_async_task
                   ^
SyntaxError: invalid syntax
[2023-09-25T15:48:46.486+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:48:46.502+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.028 seconds
[2023-09-25T15:49:00.734+0700] {processor.py:157} INFO - Started process (PID=3961) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:00.735+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:49:00.736+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:49:00.736+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:00.743+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:49:00.743+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 167
    python_callable=run_my_async_task
                   ^
SyntaxError: invalid syntax
[2023-09-25T15:49:00.744+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:00.762+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.031 seconds
[2023-09-25T15:49:14.130+0700] {processor.py:157} INFO - Started process (PID=4012) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:14.131+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:49:14.133+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:49:14.132+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:14.138+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:49:14.138+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 167
    python_callable=run_my_async_task
                   ^
SyntaxError: invalid syntax
[2023-09-25T15:49:14.139+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:14.157+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.029 seconds
[2023-09-25T15:49:44.853+0700] {processor.py:157} INFO - Started process (PID=4067) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:44.854+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:49:44.855+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:49:44.855+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:44.863+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:49:44.862+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 167
    python_callable=run_my_async_task
                   ^
SyntaxError: invalid syntax
[2023-09-25T15:49:44.864+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:49:44.884+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.034 seconds
[2023-09-25T15:50:15.006+0700] {processor.py:157} INFO - Started process (PID=4122) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:15.008+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:50:15.009+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:50:15.009+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:15.017+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:50:15.016+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 167
    python_callable=run_my_async_task
                   ^
SyntaxError: invalid syntax
[2023-09-25T15:50:15.018+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:15.037+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.034 seconds
[2023-09-25T15:50:38.738+0700] {processor.py:157} INFO - Started process (PID=4170) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:38.740+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:50:38.741+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:50:38.740+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:39.049+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:50:39.044+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:50:39.050+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:39.065+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.330 seconds
[2023-09-25T15:50:47.138+0700] {processor.py:157} INFO - Started process (PID=4178) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:47.140+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:50:47.141+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:50:47.141+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:47.466+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:50:47.464+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:50:47.467+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:50:47.483+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.348 seconds
[2023-09-25T15:51:18.099+0700] {processor.py:157} INFO - Started process (PID=4234) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:51:18.102+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:51:18.103+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:51:18.103+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:51:18.390+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:51:18.388+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:51:18.391+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:51:18.404+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.309 seconds
[2023-09-25T15:51:48.988+0700] {processor.py:157} INFO - Started process (PID=4290) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:51:48.989+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:51:48.990+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:51:48.990+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:51:49.267+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:51:49.265+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:51:49.268+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:51:49.282+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.296 seconds
[2023-09-25T15:52:19.432+0700] {processor.py:157} INFO - Started process (PID=4346) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:52:19.434+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:52:19.436+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:52:19.435+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:52:19.754+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:52:19.752+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:52:19.755+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:52:19.771+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.342 seconds
[2023-09-25T15:52:50.184+0700] {processor.py:157} INFO - Started process (PID=4402) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:52:50.186+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:52:50.188+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:52:50.187+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:52:50.512+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:52:50.510+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:52:50.513+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:52:50.528+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.347 seconds
[2023-09-25T15:53:20.802+0700] {processor.py:157} INFO - Started process (PID=4458) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:53:20.804+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:53:20.805+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:53:20.805+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:53:21.117+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:53:21.114+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:53:21.118+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:53:21.133+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.333 seconds
[2023-09-25T15:53:51.536+0700] {processor.py:157} INFO - Started process (PID=4515) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:53:51.538+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:53:51.540+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:53:51.539+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:53:51.827+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:53:51.825+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:53:51.828+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:53:51.841+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.310 seconds
[2023-09-25T15:54:22.702+0700] {processor.py:157} INFO - Started process (PID=4571) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:54:22.704+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:54:22.705+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:54:22.705+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:54:22.973+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:54:22.971+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:54:22.973+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:54:22.986+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.288 seconds
[2023-09-25T15:54:53.159+0700] {processor.py:157} INFO - Started process (PID=4626) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:54:53.160+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:54:53.162+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:54:53.161+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:54:53.457+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:54:53.455+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:54:53.458+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:54:53.472+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.316 seconds
[2023-09-25T15:55:23.579+0700] {processor.py:157} INFO - Started process (PID=4682) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:55:23.580+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:55:23.581+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:55:23.581+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:55:23.866+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:55:23.860+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:55:23.867+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:55:23.880+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.305 seconds
[2023-09-25T15:55:54.118+0700] {processor.py:157} INFO - Started process (PID=4738) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:55:54.134+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:55:54.136+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:55:54.136+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:55:54.429+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:55:54.427+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:55:54.430+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:55:54.442+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.328 seconds
[2023-09-25T15:56:25.211+0700] {processor.py:157} INFO - Started process (PID=4794) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:56:25.212+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:56:25.213+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:56:25.212+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:56:25.413+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:56:25.410+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:56:25.413+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:56:25.428+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.220 seconds
[2023-09-25T15:56:55.990+0700] {processor.py:157} INFO - Started process (PID=4850) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:56:55.991+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:56:55.993+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:56:55.992+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:56:56.196+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:56:56.193+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:56:56.197+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:56:56.213+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.226 seconds
[2023-09-25T15:57:26.705+0700] {processor.py:157} INFO - Started process (PID=4906) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:57:26.707+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:57:26.708+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:57:26.707+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:57:26.926+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:57:26.923+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:57:26.927+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:57:26.941+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T15:57:57.282+0700] {processor.py:157} INFO - Started process (PID=4962) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:57:57.285+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:57:57.286+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:57:57.286+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:57:57.490+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:57:57.488+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:57:57.491+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:57:57.506+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.227 seconds
[2023-09-25T15:58:28.003+0700] {processor.py:157} INFO - Started process (PID=5017) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:58:28.006+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:58:28.007+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:58:28.006+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:58:28.211+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:58:28.208+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:58:28.212+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:58:28.227+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.226 seconds
[2023-09-25T15:58:58.723+0700] {processor.py:157} INFO - Started process (PID=5074) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:58:58.725+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:58:58.727+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:58:58.727+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:58:58.930+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:58:58.928+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:58:58.931+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:58:58.945+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.226 seconds
[2023-09-25T15:59:29.538+0700] {processor.py:157} INFO - Started process (PID=5130) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:59:29.541+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T15:59:29.542+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:59:29.542+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:59:29.737+0700] {logging_mixin.py:151} INFO - [2023-09-25T15:59:29.734+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T15:59:29.738+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T15:59:29.752+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.218 seconds
[2023-09-25T16:00:00.291+0700] {processor.py:157} INFO - Started process (PID=5185) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:00:00.292+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:00:00.294+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:00:00.294+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:00:00.495+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:00:00.493+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:00:00.496+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:00:00.512+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.225 seconds
[2023-09-25T16:00:30.951+0700] {processor.py:157} INFO - Started process (PID=5242) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:00:30.952+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:00:30.954+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:00:30.953+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:00:31.172+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:00:31.169+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:00:31.174+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:00:31.192+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T16:01:01.595+0700] {processor.py:157} INFO - Started process (PID=5298) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:01:01.597+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:01:01.599+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:01:01.598+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:01:01.807+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:01:01.804+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:01:01.808+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:01:01.825+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.234 seconds
[2023-09-25T16:01:32.212+0700] {processor.py:157} INFO - Started process (PID=5354) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:01:32.213+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:01:32.214+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:01:32.214+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:01:32.423+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:01:32.419+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:01:32.424+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:01:32.447+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T16:02:02.957+0700] {processor.py:157} INFO - Started process (PID=5411) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:02:02.959+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:02:02.961+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:02:02.960+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:02:03.150+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:02:03.148+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:02:03.151+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:02:03.165+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.212 seconds
[2023-09-25T16:02:33.719+0700] {processor.py:157} INFO - Started process (PID=5467) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:02:33.722+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:02:33.724+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:02:33.724+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:02:33.917+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:02:33.914+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:02:33.919+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:02:33.933+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.219 seconds
[2023-09-25T16:03:04.333+0700] {processor.py:157} INFO - Started process (PID=5523) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:03:04.335+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:03:04.336+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:03:04.336+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:03:04.545+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:03:04.542+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:03:04.546+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:03:04.565+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.236 seconds
[2023-09-25T16:03:35.047+0700] {processor.py:157} INFO - Started process (PID=5579) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:03:35.048+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:03:35.050+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:03:35.049+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:03:35.261+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:03:35.258+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:03:35.262+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:03:35.279+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.235 seconds
[2023-09-25T16:04:05.719+0700] {processor.py:157} INFO - Started process (PID=5635) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:04:05.721+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:04:05.723+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:04:05.722+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:04:05.934+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:04:05.931+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:04:05.935+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:04:05.961+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T16:04:36.476+0700] {processor.py:157} INFO - Started process (PID=5691) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:04:36.478+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:04:36.480+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:04:36.479+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:04:36.697+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:04:36.694+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:04:36.699+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:04:36.716+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T16:05:07.073+0700] {processor.py:157} INFO - Started process (PID=5747) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:05:07.074+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:05:07.075+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:05:07.075+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:05:07.289+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:05:07.286+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:05:07.290+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:05:07.306+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.237 seconds
[2023-09-25T16:05:37.565+0700] {processor.py:157} INFO - Started process (PID=5803) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:05:37.568+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:05:37.569+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:05:37.569+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:05:37.779+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:05:37.776+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:05:37.780+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:05:37.795+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.234 seconds
[2023-09-25T16:06:08.241+0700] {processor.py:157} INFO - Started process (PID=5858) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:06:08.243+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:06:08.244+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:06:08.244+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:06:08.463+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:06:08.460+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:06:08.464+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:06:08.481+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T16:06:38.886+0700] {processor.py:157} INFO - Started process (PID=5914) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:06:38.888+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:06:38.890+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:06:38.889+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:06:39.098+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:06:39.095+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:06:39.099+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:06:39.115+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.233 seconds
[2023-09-25T16:07:09.435+0700] {processor.py:157} INFO - Started process (PID=5969) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:09.437+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:07:09.438+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:07:09.438+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:09.639+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:07:09.637+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:07:09.640+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:09.654+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.224 seconds
[2023-09-25T16:07:40.107+0700] {processor.py:157} INFO - Started process (PID=6026) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:40.110+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:07:40.111+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:07:40.111+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:40.307+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:07:40.304+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:07:40.308+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:40.324+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.221 seconds
[2023-09-25T16:07:54.665+0700] {processor.py:157} INFO - Started process (PID=6039) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:54.666+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:07:54.667+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:07:54.667+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:54.887+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:07:54.884+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:07:54.888+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:07:54.906+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T16:09:00.635+0700] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:00.637+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:09:00.640+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:00.639+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:01.365+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:01.363+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:09:01.367+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:01.383+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.751 seconds
[2023-09-25T16:09:31.626+0700] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:31.629+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:09:31.631+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:31.631+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:31.844+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:31.842+0700] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/crawlInvest.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 56, in getattr_with_deprecation
    return getattr(importlib.import_module(new_module), new_class_name)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'airflow.providers.microsoft.mssql'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/crawlInvest.py", line 20, in <module>
    from airflow.operators.mssql_operator import MsSqlOperator
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/deprecation_tools.py", line 63, in getattr_with_deprecation
    raise ImportError(error_message) from e
ImportError: Could not import `airflow.providers.microsoft.mssql.operators.mssql.MsSqlOperator` while trying to import `airflow.operators.mssql_operator.MsSqlOperator`.
[2023-09-25T16:09:31.845+0700] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:31.862+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.239 seconds
[2023-09-25T16:09:37.037+0700] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:37.038+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:09:37.040+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:37.040+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:37.262+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:09:37.325+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:37.325+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T16:09:37.327+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:37.327+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:09:37.339+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:09:37.339+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:09:37.357+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.323 seconds
[2023-09-25T16:10:07.434+0700] {processor.py:157} INFO - Started process (PID=191) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:10:07.436+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:10:07.439+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:10:07.439+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:10:07.642+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:10:07.658+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:10:07.657+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:10:07.671+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:10:07.671+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:10:07.681+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T16:10:38.096+0700] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:10:38.098+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:10:38.101+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:10:38.101+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:10:38.316+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:10:38.336+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:10:38.336+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:10:38.353+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:10:38.353+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:10:38.367+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.274 seconds
[2023-09-25T16:11:08.550+0700] {processor.py:157} INFO - Started process (PID=303) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:11:08.552+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:11:08.556+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:11:08.555+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:11:08.757+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:11:08.773+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:11:08.773+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:11:08.787+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:11:08.787+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:11:08.798+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T16:11:39.239+0700] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:11:39.240+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:11:39.242+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:11:39.242+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:11:39.455+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:11:39.472+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:11:39.472+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:11:39.484+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:11:39.484+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:11:39.494+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.259 seconds
[2023-09-25T16:12:09.852+0700] {processor.py:157} INFO - Started process (PID=416) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:12:09.854+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:12:09.857+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:12:09.856+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:12:10.058+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:12:10.075+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:12:10.074+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:12:10.087+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:12:10.087+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:12:10.098+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T16:12:40.543+0700] {processor.py:157} INFO - Started process (PID=472) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:12:40.546+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:12:40.549+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:12:40.549+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:12:40.758+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:12:40.773+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:12:40.773+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:12:40.787+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:12:40.787+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:12:40.797+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T16:13:10.950+0700] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:13:10.952+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:13:10.956+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:13:10.955+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:13:11.153+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:13:11.168+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:13:11.168+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:13:11.180+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:13:11.180+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:13:11.192+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.248 seconds
[2023-09-25T16:13:41.526+0700] {processor.py:157} INFO - Started process (PID=584) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:13:41.527+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:13:41.530+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:13:41.529+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:13:41.723+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:13:41.739+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:13:41.739+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:13:41.752+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:13:41.752+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:13:41.761+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T16:14:11.935+0700] {processor.py:157} INFO - Started process (PID=640) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:14:11.937+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:14:11.939+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:14:11.939+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:14:12.141+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:14:12.159+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:14:12.159+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:14:12.174+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:14:12.174+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:14:12.188+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T16:14:43.043+0700] {processor.py:157} INFO - Started process (PID=696) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:14:43.044+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:14:43.046+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:14:43.046+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:14:43.244+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:14:43.260+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:14:43.260+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:14:43.273+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:14:43.273+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:14:43.284+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T16:15:14.053+0700] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:15:14.055+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:15:14.057+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:15:14.057+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:15:14.271+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:15:14.289+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:15:14.289+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:15:14.304+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:15:14.304+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:15:14.316+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T16:15:44.759+0700] {processor.py:157} INFO - Started process (PID=807) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:15:44.760+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:15:44.762+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:15:44.762+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:15:44.972+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:15:44.992+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:15:44.991+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:15:45.007+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:15:45.007+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:15:45.021+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.266 seconds
[2023-09-25T16:16:15.555+0700] {processor.py:157} INFO - Started process (PID=863) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:16:15.557+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:16:15.561+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:16:15.560+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:16:15.769+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:16:15.784+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:16:15.784+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:16:15.797+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:16:15.797+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:16:15.808+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T16:16:46.138+0700] {processor.py:157} INFO - Started process (PID=919) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:16:46.139+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:16:46.142+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:16:46.142+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:16:46.336+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:16:46.352+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:16:46.352+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:16:46.365+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:16:46.365+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:16:46.374+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.241 seconds
[2023-09-25T16:17:16.744+0700] {processor.py:157} INFO - Started process (PID=975) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:17:16.745+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:17:16.747+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:17:16.747+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:17:16.955+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:17:16.972+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:17:16.972+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:17:16.985+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:17:16.985+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:17:16.997+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T16:17:47.570+0700] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:17:47.572+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:17:47.575+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:17:47.574+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:17:47.768+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:17:47.783+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:17:47.783+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:17:47.796+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:17:47.796+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:17:47.808+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T16:18:18.304+0700] {processor.py:157} INFO - Started process (PID=1087) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:18:18.306+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:18:18.309+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:18:18.309+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:18:18.510+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:18:18.526+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:18:18.526+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:18:18.540+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:18:18.540+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:18:18.551+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.251 seconds
[2023-09-25T16:18:48.843+0700] {processor.py:157} INFO - Started process (PID=1143) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:18:48.845+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:18:48.848+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:18:48.848+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:18:49.046+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:18:49.061+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:18:49.061+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:18:49.073+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:18:49.073+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:18:49.085+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.247 seconds
[2023-09-25T16:19:19.511+0700] {processor.py:157} INFO - Started process (PID=1198) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:19:19.512+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:19:19.515+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:19:19.514+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:19:19.726+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:19:19.745+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:19:19.745+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:19:19.760+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:19:19.760+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:19:19.772+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T16:19:50.043+0700] {processor.py:157} INFO - Started process (PID=1254) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:19:50.045+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:19:50.048+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:19:50.047+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:19:50.242+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:19:50.258+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:19:50.258+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:19:50.271+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:19:50.271+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:19:50.283+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T16:20:20.806+0700] {processor.py:157} INFO - Started process (PID=1310) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:20:20.808+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:20:20.812+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:20:20.811+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:20:21.004+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:20:21.020+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:20:21.020+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:20:21.032+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:20:21.032+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:20:21.042+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.239 seconds
[2023-09-25T16:20:51.290+0700] {processor.py:157} INFO - Started process (PID=1365) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:20:51.291+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:20:51.293+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:20:51.292+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:20:51.480+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:20:51.497+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:20:51.496+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:20:51.511+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:20:51.511+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:20:51.521+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.234 seconds
[2023-09-25T16:21:21.983+0700] {processor.py:157} INFO - Started process (PID=1422) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:21:21.985+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:21:21.988+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:21:21.987+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:21:22.196+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:21:22.214+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:21:22.213+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:21:22.229+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:21:22.229+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:21:22.244+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.263 seconds
[2023-09-25T16:21:52.603+0700] {processor.py:157} INFO - Started process (PID=1478) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:21:52.604+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:21:52.606+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:21:52.606+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:21:52.808+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:21:52.826+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:21:52.826+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:21:52.840+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:21:52.840+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:21:52.854+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T16:22:23.130+0700] {processor.py:157} INFO - Started process (PID=1534) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:22:23.132+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:22:23.136+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:22:23.135+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:22:23.342+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:22:23.358+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:22:23.358+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:22:23.374+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:22:23.374+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:22:23.385+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.259 seconds
[2023-09-25T16:22:53.684+0700] {processor.py:157} INFO - Started process (PID=1591) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:22:53.686+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:22:53.689+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:22:53.689+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:22:53.886+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:22:53.903+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:22:53.902+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:22:53.915+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:22:53.915+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:22:53.926+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.248 seconds
[2023-09-25T16:24:01.706+0700] {processor.py:157} INFO - Started process (PID=30) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:24:01.707+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:24:01.710+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:01.710+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:24:02.537+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:24:02.655+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:02.655+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T16:24:02.656+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:02.656+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:24:02.672+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:02.671+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:24:02.693+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.991 seconds
[2023-09-25T16:24:33.731+0700] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:24:33.732+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:24:33.735+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:33.735+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:24:33.942+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:24:33.961+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:33.961+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:24:33.977+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:24:33.977+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:24:33.991+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.262 seconds
[2023-09-25T16:25:04.591+0700] {processor.py:157} INFO - Started process (PID=146) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:25:04.593+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:25:04.597+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:25:04.596+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:25:04.796+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:25:04.816+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:25:04.816+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:25:04.830+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:25:04.830+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:25:04.841+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T16:25:35.228+0700] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:25:35.230+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:25:35.234+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:25:35.233+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:25:35.439+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:25:35.455+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:25:35.455+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:25:35.469+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:25:35.469+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:25:35.480+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T16:26:05.901+0700] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:26:05.903+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:26:05.907+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:26:05.906+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:26:06.109+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:26:06.125+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:26:06.125+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:26:06.140+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:26:06.140+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:26:06.152+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T16:26:36.658+0700] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:26:36.659+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:26:36.662+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:26:36.661+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:26:36.862+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:26:36.879+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:26:36.879+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:26:36.894+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:26:36.894+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:26:36.905+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T16:27:07.422+0700] {processor.py:157} INFO - Started process (PID=370) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:27:07.424+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:27:07.427+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:27:07.426+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:27:07.623+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:27:07.639+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:27:07.638+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:27:07.653+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:27:07.653+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:27:07.664+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.247 seconds
[2023-09-25T16:27:37.939+0700] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:27:37.941+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:27:37.943+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:27:37.943+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:27:38.136+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:27:38.152+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:27:38.152+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:27:38.166+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:27:38.166+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:27:38.176+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T16:28:08.217+0700] {processor.py:157} INFO - Started process (PID=482) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:08.219+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:28:08.222+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:08.221+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:08.414+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:08.432+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:08.431+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:28:08.445+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:08.445+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:28:08.456+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T16:28:12.109+0700] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:12.111+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:28:12.114+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:12.113+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:12.326+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:12.343+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:12.342+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:28:12.357+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:12.357+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:28:12.371+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T16:28:16.343+0700] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:16.344+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:28:16.346+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:16.346+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:16.556+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:16.574+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:16.573+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:28:16.589+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:16.589+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:28:16.605+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T16:28:25.574+0700] {processor.py:157} INFO - Started process (PID=537) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:25.576+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:28:25.579+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:25.578+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:25.778+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:25.793+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:25.793+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:28:25.806+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:25.806+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:28:25.819+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.249 seconds
[2023-09-25T16:28:56.335+0700] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:56.337+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:28:56.339+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:56.339+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:56.531+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:28:56.546+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:56.546+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:28:56.560+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:28:56.560+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:28:56.571+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.240 seconds
[2023-09-25T16:29:02.444+0700] {processor.py:157} INFO - Started process (PID=594) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:29:02.445+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:29:02.448+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:29:02.447+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:29:02.648+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:29:02.667+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:29:02.666+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:29:02.680+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:29:02.680+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:29:02.696+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T16:29:33.146+0700] {processor.py:157} INFO - Started process (PID=650) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:29:33.147+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:29:33.149+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:29:33.149+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:29:33.354+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:29:33.383+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:29:33.383+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:29:33.414+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:29:33.414+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:29:33.438+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.294 seconds
[2023-09-25T16:30:03.617+0700] {processor.py:157} INFO - Started process (PID=706) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:30:03.619+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:30:03.622+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:30:03.621+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:30:03.834+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:30:03.852+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:30:03.851+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:30:03.867+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:30:03.867+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:30:03.880+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.268 seconds
[2023-09-25T16:30:34.137+0700] {processor.py:157} INFO - Started process (PID=762) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:30:34.139+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:30:34.143+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:30:34.142+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:30:34.348+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:30:34.364+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:30:34.363+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:30:34.378+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:30:34.378+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:30:34.388+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T16:31:04.608+0700] {processor.py:157} INFO - Started process (PID=818) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:31:04.609+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:31:04.612+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:31:04.611+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:31:04.823+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:31:04.838+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:31:04.838+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:31:04.851+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:31:04.851+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:31:04.862+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T16:31:35.188+0700] {processor.py:157} INFO - Started process (PID=874) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:31:35.190+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:31:35.192+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:31:35.191+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:31:35.393+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:31:35.411+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:31:35.411+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:31:35.425+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:31:35.425+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:31:35.438+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T16:32:05.904+0700] {processor.py:157} INFO - Started process (PID=930) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:32:05.905+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:32:05.908+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:32:05.907+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:32:06.120+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:32:06.137+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:32:06.137+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:32:06.152+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:32:06.152+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:32:06.165+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.264 seconds
[2023-09-25T16:32:36.601+0700] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:32:36.602+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:32:36.606+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:32:36.605+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:32:36.819+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:32:36.835+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:32:36.834+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:32:36.848+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:32:36.848+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:32:36.860+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.264 seconds
[2023-09-25T16:33:07.473+0700] {processor.py:157} INFO - Started process (PID=1042) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:33:07.475+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:33:07.478+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:33:07.477+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:33:07.679+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:33:07.694+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:33:07.694+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:33:07.708+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:33:07.707+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:33:07.718+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.249 seconds
[2023-09-25T16:36:45.610+0700] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:36:45.612+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:36:45.614+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:36:45.614+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:36:46.421+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:36:46.567+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:36:46.567+0700] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:crawl_dag_v01' as access control is unset.
[2023-09-25T16:36:46.568+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:36:46.568+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:36:46.585+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:36:46.585+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:36:46.610+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 1.004 seconds
[2023-09-25T16:37:16.698+0700] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:37:16.700+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:37:16.703+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:37:16.703+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:37:16.918+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:37:16.937+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:37:16.937+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:37:16.958+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:37:16.957+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:37:16.972+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.278 seconds
[2023-09-25T16:37:47.702+0700] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:37:47.703+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:37:47.705+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:37:47.705+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:37:47.927+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:37:47.947+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:37:47.947+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:37:47.963+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:37:47.963+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:37:47.976+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.277 seconds
[2023-09-25T16:38:06.374+0700] {processor.py:157} INFO - Started process (PID=191) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:38:06.376+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:38:06.378+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:38:06.378+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:38:06.589+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:38:06.607+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:38:06.606+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:38:06.622+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:38:06.621+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:38:06.636+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.265 seconds
[2023-09-25T16:38:37.169+0700] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:38:37.171+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:38:37.174+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:38:37.174+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:38:37.428+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:38:37.451+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:38:37.450+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:38:37.466+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:38:37.466+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:38:37.481+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.316 seconds
[2023-09-25T16:39:07.618+0700] {processor.py:157} INFO - Started process (PID=303) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:39:07.619+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:39:07.621+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:39:07.621+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:39:07.832+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:39:07.849+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:39:07.848+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:39:07.865+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:39:07.864+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:39:07.876+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.261 seconds
[2023-09-25T16:39:38.292+0700] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:39:38.293+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:39:38.296+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:39:38.295+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:39:38.492+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:39:38.510+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:39:38.509+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:39:38.522+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:39:38.522+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:39:38.532+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T16:40:08.581+0700] {processor.py:157} INFO - Started process (PID=415) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:08.583+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:40:08.587+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:08.586+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:08.794+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:08.811+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:08.810+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:40:08.823+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:08.823+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:40:08.833+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T16:40:28.060+0700] {processor.py:157} INFO - Started process (PID=471) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:28.061+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:40:28.064+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:28.063+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:28.283+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:28.302+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:28.301+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:40:28.317+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:28.317+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:40:28.335+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.277 seconds
[2023-09-25T16:40:58.641+0700] {processor.py:157} INFO - Started process (PID=527) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:58.643+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:40:58.645+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:58.644+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:58.852+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:40:58.867+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:58.867+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:40:58.881+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:40:58.880+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:40:58.892+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T16:41:29.206+0700] {processor.py:157} INFO - Started process (PID=583) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:41:29.208+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:41:29.210+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:41:29.209+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:41:29.408+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:41:29.424+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:41:29.424+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:41:29.442+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:41:29.442+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:41:29.472+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.268 seconds
[2023-09-25T16:41:59.767+0700] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:41:59.768+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:41:59.771+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:41:59.771+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:41:59.984+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:42:00.002+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:42:00.001+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:42:00.017+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:42:00.017+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:42:00.032+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.268 seconds
[2023-09-25T16:42:30.397+0700] {processor.py:157} INFO - Started process (PID=695) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:42:30.399+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:42:30.402+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:42:30.402+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:42:30.600+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:42:30.617+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:42:30.617+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:42:30.631+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:42:30.631+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:42:30.644+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.252 seconds
[2023-09-25T16:43:01.069+0700] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:01.071+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:43:01.075+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:01.075+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:01.270+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:01.286+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:01.286+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:43:01.299+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:01.299+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:43:01.310+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T16:43:31.967+0700] {processor.py:157} INFO - Started process (PID=807) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:31.968+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:43:31.971+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:31.971+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:32.170+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:32.187+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:32.187+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:43:32.200+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:32.200+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:43:32.211+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.249 seconds
[2023-09-25T16:43:49.238+0700] {processor.py:157} INFO - Started process (PID=817) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:49.240+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:43:49.243+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:49.242+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:49.459+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:49.475+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:49.475+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:43:49.487+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:49.487+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:43:49.501+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.266 seconds
[2023-09-25T16:43:57.252+0700] {processor.py:157} INFO - Started process (PID=852) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:57.254+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:43:57.256+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:57.256+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:57.467+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:43:57.485+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:57.485+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:43:57.501+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:43:57.500+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:43:57.517+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T16:44:27.751+0700] {processor.py:157} INFO - Started process (PID=906) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:44:27.752+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:44:27.754+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:44:27.753+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:44:27.960+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:44:27.975+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:44:27.975+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:44:27.989+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:44:27.989+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:44:28.002+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T16:44:58.521+0700] {processor.py:157} INFO - Started process (PID=963) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:44:58.523+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:44:58.525+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:44:58.524+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:44:58.723+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:44:58.740+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:44:58.739+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:44:58.754+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:44:58.754+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:44:58.765+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T16:45:19.653+0700] {processor.py:157} INFO - Started process (PID=987) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:19.654+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:45:19.657+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:19.657+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:19.870+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:19.889+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:19.889+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:45:19.905+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:19.905+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:45:19.922+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.273 seconds
[2023-09-25T16:45:26.080+0700] {processor.py:157} INFO - Started process (PID=989) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:26.081+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:45:26.084+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:26.083+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:26.309+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:26.332+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:26.331+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:45:26.347+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:26.347+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:45:26.364+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.287 seconds
[2023-09-25T16:45:54.884+0700] {processor.py:157} INFO - Started process (PID=1045) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:54.885+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:45:54.888+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:54.887+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:55.098+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:45:55.118+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:55.118+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:45:55.132+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:45:55.132+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:45:55.147+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.266 seconds
[2023-09-25T16:46:25.862+0700] {processor.py:157} INFO - Started process (PID=1100) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:46:25.863+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:46:25.866+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:46:25.866+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:46:26.078+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:46:26.097+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:46:26.096+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:46:26.112+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:46:26.112+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:46:26.124+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T16:46:56.404+0700] {processor.py:157} INFO - Started process (PID=1156) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:46:56.405+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:46:56.407+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:46:56.407+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:46:56.617+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:46:56.635+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:46:56.635+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:46:56.650+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:46:56.650+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:46:56.662+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.261 seconds
[2023-09-25T16:47:26.816+0700] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:47:26.817+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:47:26.820+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:47:26.819+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:47:27.007+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:47:27.024+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:47:27.023+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:47:27.038+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:47:27.038+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:47:27.052+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.239 seconds
[2023-09-25T16:47:57.515+0700] {processor.py:157} INFO - Started process (PID=1268) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:47:57.516+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:47:57.518+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:47:57.518+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:47:57.718+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:47:57.739+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:47:57.739+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:47:57.764+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:47:57.764+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:47:57.776+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.264 seconds
[2023-09-25T16:48:27.939+0700] {processor.py:157} INFO - Started process (PID=1324) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:48:27.940+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:48:27.942+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:48:27.942+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:48:28.140+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:48:28.155+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:48:28.155+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:48:28.168+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:48:28.167+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:48:28.179+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.242 seconds
[2023-09-25T16:48:58.369+0700] {processor.py:157} INFO - Started process (PID=1379) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:48:58.371+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:48:58.375+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:48:58.374+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:48:58.567+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:48:58.582+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:48:58.582+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:48:58.594+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:48:58.594+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:48:58.605+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.240 seconds
[2023-09-25T16:49:28.909+0700] {processor.py:157} INFO - Started process (PID=1435) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:49:28.910+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:49:28.913+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:49:28.913+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:49:29.100+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:49:29.115+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:49:29.115+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:49:29.127+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:49:29.127+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:49:29.138+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.234 seconds
[2023-09-25T16:49:59.204+0700] {processor.py:157} INFO - Started process (PID=1491) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:49:59.205+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:49:59.208+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:49:59.207+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:49:59.414+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:49:59.430+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:49:59.430+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:49:59.444+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:49:59.443+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:49:59.454+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T16:50:29.985+0700] {processor.py:157} INFO - Started process (PID=1547) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:29.986+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:50:29.989+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:29.988+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:30.188+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:30.205+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:30.205+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:50:30.218+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:30.218+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:50:30.229+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.249 seconds
[2023-09-25T16:50:34.399+0700] {processor.py:157} INFO - Started process (PID=1575) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:34.400+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:50:34.402+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:34.402+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:34.613+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:34.630+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:34.630+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:50:34.644+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:34.644+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:50:34.752+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.356 seconds
[2023-09-25T16:50:42.511+0700] {processor.py:157} INFO - Started process (PID=1604) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:42.512+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:50:42.514+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:42.514+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:42.728+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:50:42.748+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:42.747+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:50:42.764+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:50:42.764+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:50:42.782+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.273 seconds
[2023-09-25T16:51:13.014+0700] {processor.py:157} INFO - Started process (PID=1660) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:51:13.015+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:51:13.018+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:51:13.017+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:51:13.213+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:51:13.230+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:51:13.230+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:51:13.243+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:51:13.243+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:51:13.254+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T16:51:30.501+0700] {processor.py:157} INFO - Started process (PID=1662) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:51:30.503+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:51:30.506+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:51:30.505+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:51:30.707+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:51:30.726+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:51:30.725+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:51:30.740+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:51:30.740+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:51:30.756+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T16:52:01.230+0700] {processor.py:157} INFO - Started process (PID=1717) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:52:01.232+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:52:01.235+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:52:01.234+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:52:01.421+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:52:01.437+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:52:01.436+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:52:01.449+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:52:01.449+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:52:01.459+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.234 seconds
[2023-09-25T16:52:31.805+0700] {processor.py:157} INFO - Started process (PID=1773) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:52:31.807+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:52:31.811+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:52:31.810+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:52:32.014+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:52:32.030+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:52:32.029+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:52:32.131+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:52:32.131+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:52:32.143+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.343 seconds
[2023-09-25T16:53:02.345+0700] {processor.py:157} INFO - Started process (PID=1829) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:53:02.347+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:53:02.349+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:53:02.349+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:53:02.536+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:53:02.551+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:53:02.551+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:53:02.645+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:53:02.645+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:53:02.655+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.314 seconds
[2023-09-25T16:53:32.957+0700] {processor.py:157} INFO - Started process (PID=1886) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:53:32.958+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:53:32.961+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:53:32.961+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:53:33.169+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:53:33.187+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:53:33.186+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:53:33.202+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:53:33.201+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:53:33.215+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.262 seconds
[2023-09-25T16:54:03.569+0700] {processor.py:157} INFO - Started process (PID=1942) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:54:03.570+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:54:03.574+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:54:03.573+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:54:03.854+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:54:03.867+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:54:03.867+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:54:03.878+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:54:03.878+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:54:03.888+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.324 seconds
[2023-09-25T16:54:34.196+0700] {processor.py:157} INFO - Started process (PID=1998) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:54:34.198+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:54:34.202+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:54:34.201+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:54:34.413+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:54:34.431+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:54:34.430+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:54:34.446+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:54:34.445+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:54:34.459+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.268 seconds
[2023-09-25T16:55:04.794+0700] {processor.py:157} INFO - Started process (PID=2054) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:55:04.796+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:55:04.800+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:55:04.799+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:55:05.012+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:55:05.031+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:55:05.031+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:55:05.135+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:55:05.135+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:55:05.148+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.357 seconds
[2023-09-25T16:55:35.267+0700] {processor.py:157} INFO - Started process (PID=2109) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:55:35.269+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:55:35.273+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:55:35.273+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:55:35.469+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:55:35.486+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:55:35.486+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:55:35.586+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:55:35.586+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:55:35.596+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.335 seconds
[2023-09-25T16:56:05.895+0700] {processor.py:157} INFO - Started process (PID=2165) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:05.899+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:56:05.902+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:05.901+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:06.196+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:06.210+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:06.210+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:56:06.222+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:06.222+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:56:06.233+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.341 seconds
[2023-09-25T16:56:23.527+0700] {processor.py:157} INFO - Started process (PID=2221) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:23.528+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:56:23.530+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:23.530+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:23.836+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:23.851+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:23.851+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:56:23.864+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:23.864+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:56:23.878+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.354 seconds
[2023-09-25T16:56:54.237+0700] {processor.py:157} INFO - Started process (PID=2277) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:54.239+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:56:54.242+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:54.242+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:54.522+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:56:54.536+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:54.536+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:56:54.547+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:56:54.547+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:56:54.557+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.325 seconds
[2023-09-25T16:57:24.912+0700] {processor.py:157} INFO - Started process (PID=2333) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:24.914+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:57:24.917+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:24.917+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:25.194+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:25.208+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:25.208+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:57:25.219+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:25.219+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:57:25.228+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.321 seconds
[2023-09-25T16:57:43.645+0700] {processor.py:157} INFO - Started process (PID=2368) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:43.646+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:57:43.648+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:43.648+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:43.952+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:43.967+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:43.967+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:57:43.981+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:43.981+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:57:43.994+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.351 seconds
[2023-09-25T16:57:48.762+0700] {processor.py:157} INFO - Started process (PID=2391) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:48.763+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:57:48.765+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:48.765+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:49.062+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:57:49.076+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:49.076+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:57:49.088+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:57:49.088+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:57:49.101+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.342 seconds
[2023-09-25T16:58:04.266+0700] {processor.py:157} INFO - Started process (PID=2393) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:58:04.268+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:58:04.271+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:58:04.271+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:58:04.574+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:58:04.590+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:58:04.589+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:58:04.602+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:58:04.602+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:58:04.616+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.355 seconds
[2023-09-25T16:58:35.361+0700] {processor.py:157} INFO - Started process (PID=2449) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:58:35.362+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:58:35.365+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:58:35.364+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:58:35.647+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:58:35.660+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:58:35.660+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:58:35.673+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:58:35.672+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:58:35.682+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.325 seconds
[2023-09-25T16:59:06.083+0700] {processor.py:157} INFO - Started process (PID=2505) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:06.084+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:59:06.087+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:06.087+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:06.364+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:06.378+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:06.377+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:59:06.388+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:06.388+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:59:06.399+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.321 seconds
[2023-09-25T16:59:36.814+0700] {processor.py:157} INFO - Started process (PID=2561) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:36.815+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:59:36.819+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:36.818+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:37.108+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:37.122+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:37.122+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:59:37.133+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:37.133+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:59:37.143+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.333 seconds
[2023-09-25T16:59:54.515+0700] {processor.py:157} INFO - Started process (PID=2617) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:54.517+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T16:59:54.519+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:54.519+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:54.821+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T16:59:54.844+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:54.844+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T16:59:54.860+0700] {logging_mixin.py:151} INFO - [2023-09-25T16:59:54.860+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T16:59:54.879+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.367 seconds
[2023-09-25T17:00:02.854+0700] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:02.855+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:00:02.857+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:02.857+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:03.171+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:03.187+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:03.187+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:00:03.200+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:03.200+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:00:03.215+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.364 seconds
[2023-09-25T17:00:33.942+0700] {processor.py:157} INFO - Started process (PID=2675) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:33.943+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:00:33.945+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:33.945+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:34.239+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:34.255+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:34.255+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:00:34.270+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:34.270+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:00:34.282+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.343 seconds
[2023-09-25T17:00:38.281+0700] {processor.py:157} INFO - Started process (PID=2677) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:38.282+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:00:38.284+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:38.284+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:38.580+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:38.595+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:38.595+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:00:38.607+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:38.607+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:00:38.621+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.343 seconds
[2023-09-25T17:00:45.668+0700] {processor.py:157} INFO - Started process (PID=2701) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:45.670+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:00:45.672+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:45.671+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:45.984+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:00:46.003+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:46.003+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:00:46.015+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:00:46.015+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:00:46.030+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.365 seconds
[2023-09-25T17:01:16.169+0700] {processor.py:157} INFO - Started process (PID=2749) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:01:16.171+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:01:16.174+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:01:16.174+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:01:16.499+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:01:16.514+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:01:16.514+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:01:16.527+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:01:16.527+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:01:16.537+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.373 seconds
[2023-09-25T17:01:46.836+0700] {processor.py:157} INFO - Started process (PID=2804) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:01:46.838+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:01:46.841+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:01:46.840+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:01:47.126+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:01:47.140+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:01:47.139+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:01:47.151+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:01:47.151+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:01:47.162+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.330 seconds
[2023-09-25T17:02:08.300+0700] {processor.py:157} INFO - Started process (PID=2846) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:08.302+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:02:08.304+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:08.304+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:08.600+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:08.614+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:08.614+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:02:08.628+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:08.628+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:02:08.641+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.344 seconds
[2023-09-25T17:02:39.197+0700] {processor.py:157} INFO - Started process (PID=2902) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:39.198+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:02:39.201+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:39.201+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:39.488+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:39.502+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:39.501+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:02:39.513+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:39.513+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:02:39.524+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.330 seconds
[2023-09-25T17:02:41.582+0700] {processor.py:157} INFO - Started process (PID=2912) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:41.583+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:02:41.586+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:41.585+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:41.875+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:02:41.890+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:41.889+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:02:41.903+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:02:41.903+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:02:41.920+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.341 seconds
[2023-09-25T17:03:12.398+0700] {processor.py:157} INFO - Started process (PID=2968) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:03:12.399+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:03:12.402+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:03:12.401+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:03:12.739+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:03:12.754+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:03:12.753+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:03:12.769+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:03:12.769+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:03:12.782+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.387 seconds
[2023-09-25T17:03:43.146+0700] {processor.py:157} INFO - Started process (PID=3024) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:03:43.147+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:03:43.149+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:03:43.149+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:03:43.421+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:03:43.435+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:03:43.435+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:03:43.447+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:03:43.447+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:03:43.457+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.314 seconds
[2023-09-25T17:04:06.789+0700] {processor.py:157} INFO - Started process (PID=3073) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:04:06.790+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:04:06.793+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:04:06.792+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:04:07.082+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:04:07.097+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:04:07.097+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:04:07.109+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:04:07.109+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:04:07.124+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.338 seconds
[2023-09-25T17:04:37.767+0700] {processor.py:157} INFO - Started process (PID=3129) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:04:37.769+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:04:37.773+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:04:37.773+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:04:38.081+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:04:38.097+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:04:38.097+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:04:38.110+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:04:38.109+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:04:38.123+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.362 seconds
[2023-09-25T17:05:08.663+0700] {processor.py:157} INFO - Started process (PID=3185) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:05:08.664+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:05:08.666+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:05:08.666+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:05:08.950+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:05:08.964+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:05:08.964+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:05:08.976+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:05:08.975+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:05:08.985+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.325 seconds
[2023-09-25T17:05:39.258+0700] {processor.py:157} INFO - Started process (PID=3241) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:05:39.260+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:05:39.263+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:05:39.263+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:05:39.537+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:05:39.550+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:05:39.550+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:05:39.561+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:05:39.561+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:05:39.571+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.317 seconds
[2023-09-25T17:06:09.856+0700] {processor.py:157} INFO - Started process (PID=3297) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:06:09.859+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:06:09.861+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:06:09.861+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:06:10.129+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:06:10.144+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:06:10.144+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:06:10.157+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:06:10.157+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:06:10.169+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.315 seconds
[2023-09-25T17:06:40.313+0700] {processor.py:157} INFO - Started process (PID=3353) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:06:40.315+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:06:40.317+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:06:40.317+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:06:40.593+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:06:40.607+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:06:40.607+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:06:40.618+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:06:40.618+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:06:40.628+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.319 seconds
[2023-09-25T17:07:11.222+0700] {processor.py:157} INFO - Started process (PID=3410) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:11.226+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:07:11.229+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:11.229+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:11.537+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:11.552+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:11.551+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:07:11.565+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:11.565+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:07:11.576+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.357 seconds
[2023-09-25T17:07:41.639+0700] {processor.py:157} INFO - Started process (PID=3466) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:41.640+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:07:41.642+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:41.642+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:41.937+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:41.954+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:41.953+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:07:41.968+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:41.968+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:07:41.982+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.346 seconds
[2023-09-25T17:07:46.073+0700] {processor.py:157} INFO - Started process (PID=3475) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:46.075+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:07:46.077+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:46.077+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:46.378+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:07:46.399+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:46.398+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:07:46.411+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:07:46.411+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:07:46.429+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.359 seconds
[2023-09-25T17:08:16.577+0700] {processor.py:157} INFO - Started process (PID=3531) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:08:16.580+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:08:16.584+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:08:16.583+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:08:16.882+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:08:16.896+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:08:16.896+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:08:16.908+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:08:16.908+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:08:16.920+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.348 seconds
[2023-09-25T17:08:47.553+0700] {processor.py:157} INFO - Started process (PID=3587) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:08:47.555+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:08:47.559+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:08:47.558+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:08:47.858+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:08:47.875+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:08:47.875+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:08:47.888+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:08:47.888+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:08:47.901+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.352 seconds
[2023-09-25T17:09:18.605+0700] {processor.py:157} INFO - Started process (PID=3643) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:09:18.606+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:09:18.610+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:09:18.609+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:09:18.894+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:09:18.908+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:09:18.907+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:09:18.919+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:09:18.918+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:09:18.928+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.328 seconds
[2023-09-25T17:09:49.622+0700] {processor.py:157} INFO - Started process (PID=3699) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:09:49.623+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:09:49.626+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:09:49.626+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:09:49.899+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:09:49.912+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:09:49.912+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:09:49.924+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:09:49.924+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:09:49.934+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.317 seconds
[2023-09-25T17:10:20.172+0700] {processor.py:157} INFO - Started process (PID=3755) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:10:20.173+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:10:20.176+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:10:20.175+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:10:20.441+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:10:20.454+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:10:20.454+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:10:20.466+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:10:20.466+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:10:20.476+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.307 seconds
[2023-09-25T17:10:50.757+0700] {processor.py:157} INFO - Started process (PID=3811) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:10:50.759+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:10:50.762+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:10:50.762+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:10:51.036+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:10:51.050+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:10:51.050+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:10:51.062+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:10:51.062+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:10:51.072+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.319 seconds
[2023-09-25T17:11:21.520+0700] {processor.py:157} INFO - Started process (PID=3868) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:11:21.522+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:11:21.525+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:11:21.525+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:11:21.797+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:11:21.810+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:11:21.810+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:11:21.821+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:11:21.821+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:11:21.831+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.316 seconds
[2023-09-25T17:11:52.199+0700] {processor.py:157} INFO - Started process (PID=3924) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:11:52.201+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:11:52.204+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:11:52.203+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:11:52.489+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:11:52.503+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:11:52.503+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:11:52.516+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:11:52.516+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:11:52.529+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.334 seconds
[2023-09-25T17:12:12.195+0700] {processor.py:157} INFO - Started process (PID=3973) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:12.196+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:12:12.199+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:12.198+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:12.500+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:12.516+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:12.515+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:12:12.529+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:12.528+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:12:12.543+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.351 seconds
[2023-09-25T17:12:19.326+0700] {processor.py:157} INFO - Started process (PID=3981) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:19.328+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:12:19.330+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:19.330+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:19.629+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:19.646+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:19.645+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:12:19.659+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:19.659+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:12:19.675+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.351 seconds
[2023-09-25T17:12:50.281+0700] {processor.py:157} INFO - Started process (PID=4037) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:50.283+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:12:50.286+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:50.286+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:50.559+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:12:50.572+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:50.572+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:12:50.583+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:12:50.583+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:12:50.593+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.317 seconds
[2023-09-25T17:13:21.103+0700] {processor.py:157} INFO - Started process (PID=4093) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:13:21.105+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:13:21.109+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:13:21.109+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:13:21.379+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:13:21.393+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:13:21.393+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:13:21.404+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:13:21.404+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:13:21.414+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.315 seconds
[2023-09-25T17:13:52.005+0700] {processor.py:157} INFO - Started process (PID=4149) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:13:52.007+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:13:52.010+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:13:52.010+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:13:52.278+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:13:52.292+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:13:52.292+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:13:52.303+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:13:52.303+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:13:52.313+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.312 seconds
[2023-09-25T17:14:22.794+0700] {processor.py:157} INFO - Started process (PID=4205) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:14:22.795+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:14:22.799+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:14:22.798+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:14:23.086+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:14:23.100+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:14:23.100+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:14:23.111+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:14:23.111+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:14:23.121+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.331 seconds
[2023-09-25T17:14:53.599+0700] {processor.py:157} INFO - Started process (PID=4261) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:14:53.601+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:14:53.604+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:14:53.603+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:14:53.894+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:14:53.908+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:14:53.908+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:14:53.921+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:14:53.921+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:14:53.932+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.339 seconds
[2023-09-25T17:15:24.592+0700] {processor.py:157} INFO - Started process (PID=4317) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:15:24.594+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:15:24.597+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:15:24.597+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:15:24.874+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:15:24.887+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:15:24.887+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:15:24.898+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:15:24.898+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:15:24.908+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.321 seconds
[2023-09-25T17:15:55.431+0700] {processor.py:157} INFO - Started process (PID=4373) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:15:55.433+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:15:55.436+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:15:55.435+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:15:55.712+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:15:55.726+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:15:55.726+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:15:55.737+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:15:55.737+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:15:55.746+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.320 seconds
[2023-09-25T17:16:26.156+0700] {processor.py:157} INFO - Started process (PID=4429) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:16:26.157+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:16:26.160+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:16:26.160+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:16:26.428+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:16:26.441+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:16:26.441+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:16:26.452+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:16:26.452+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:16:26.463+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.311 seconds
[2023-09-25T17:16:56.556+0700] {processor.py:157} INFO - Started process (PID=4485) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:16:56.558+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:16:56.561+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:16:56.560+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:16:56.826+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:16:56.839+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:16:56.839+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:16:56.851+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:16:56.851+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:16:56.861+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.309 seconds
[2023-09-25T17:17:27.532+0700] {processor.py:157} INFO - Started process (PID=4541) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:17:27.534+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:17:27.538+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:17:27.537+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:17:27.834+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:17:27.848+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:17:27.847+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:17:27.861+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:17:27.860+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:17:27.871+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.343 seconds
[2023-09-25T17:17:58.074+0700] {processor.py:157} INFO - Started process (PID=4597) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:17:58.076+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:17:58.079+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:17:58.079+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:17:58.364+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:17:58.378+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:17:58.377+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:17:58.391+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:17:58.391+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:17:58.402+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.333 seconds
[2023-09-25T17:18:28.507+0700] {processor.py:157} INFO - Started process (PID=4653) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:18:28.508+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:18:28.511+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:18:28.511+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:18:28.799+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:18:28.813+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:18:28.813+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:18:28.824+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:18:28.824+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:18:28.836+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.333 seconds
[2023-09-25T17:18:58.981+0700] {processor.py:157} INFO - Started process (PID=4709) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:18:58.983+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:18:58.986+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:18:58.986+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:18:59.282+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:18:59.297+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:18:59.297+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:18:59.309+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:18:59.309+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:18:59.320+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.344 seconds
[2023-09-25T17:19:29.383+0700] {processor.py:157} INFO - Started process (PID=4765) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:19:29.385+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:19:29.387+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:19:29.387+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:19:29.670+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:19:29.684+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:19:29.684+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:19:29.696+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:19:29.696+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:19:29.706+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.326 seconds
[2023-09-25T17:20:00.027+0700] {processor.py:157} INFO - Started process (PID=4820) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:20:00.029+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:20:00.033+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:20:00.032+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:20:00.240+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:20:00.255+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:20:00.255+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:20:00.268+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:20:00.267+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:20:00.278+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T17:20:30.482+0700] {processor.py:157} INFO - Started process (PID=4876) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:20:30.484+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:20:30.487+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:20:30.487+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:20:30.687+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:20:30.703+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:20:30.703+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:20:30.715+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:20:30.715+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:20:30.726+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.249 seconds
[2023-09-25T17:21:01.131+0700] {processor.py:157} INFO - Started process (PID=4932) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:21:01.133+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:21:01.135+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:21:01.134+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:21:01.340+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:21:01.359+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:21:01.358+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:21:01.373+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:21:01.373+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:21:01.386+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.258 seconds
[2023-09-25T17:21:31.651+0700] {processor.py:157} INFO - Started process (PID=4988) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:21:31.652+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:21:31.654+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:21:31.654+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:21:31.860+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:21:31.879+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:21:31.879+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:21:31.895+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:21:31.895+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:21:31.910+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.263 seconds
[2023-09-25T17:22:02.224+0700] {processor.py:157} INFO - Started process (PID=5043) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:22:02.226+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:22:02.228+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:22:02.228+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:22:02.432+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:22:02.450+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:22:02.450+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:22:02.465+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:22:02.465+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:22:02.478+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.257 seconds
[2023-09-25T17:22:32.713+0700] {processor.py:157} INFO - Started process (PID=5098) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:22:32.715+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:22:32.718+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:22:32.717+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:22:32.936+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:22:32.953+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:22:32.953+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:22:32.967+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:22:32.966+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:22:32.978+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T17:23:03.185+0700] {processor.py:157} INFO - Started process (PID=5154) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:23:03.186+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:23:03.189+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:23:03.189+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:23:03.396+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:23:03.414+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:23:03.413+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:23:03.429+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:23:03.429+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:23:03.442+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.260 seconds
[2023-09-25T17:23:33.792+0700] {processor.py:157} INFO - Started process (PID=5210) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:23:33.794+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:23:33.796+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:23:33.795+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:23:34.009+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:23:34.027+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:23:34.027+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:23:34.043+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:23:34.043+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:23:34.057+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.267 seconds
[2023-09-25T17:24:04.386+0700] {processor.py:157} INFO - Started process (PID=5266) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:24:04.387+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:24:04.390+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:24:04.390+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:24:04.604+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:24:04.623+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:24:04.623+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:24:04.640+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:24:04.640+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:24:04.652+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.270 seconds
[2023-09-25T17:24:34.948+0700] {processor.py:157} INFO - Started process (PID=5322) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:24:34.950+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:24:34.953+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:24:34.952+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:24:35.168+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:24:35.185+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:24:35.185+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:24:35.198+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:24:35.198+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:24:35.215+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.269 seconds
[2023-09-25T17:25:05.465+0700] {processor.py:157} INFO - Started process (PID=5378) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:25:05.467+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:25:05.470+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:25:05.470+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:25:05.673+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:25:05.689+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:25:05.689+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:25:05.703+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:25:05.702+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:25:05.713+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T17:25:35.932+0700] {processor.py:157} INFO - Started process (PID=5434) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:25:35.933+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:25:35.935+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:25:35.935+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:25:36.133+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:25:36.148+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:25:36.148+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:25:36.162+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:25:36.162+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:25:36.172+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.243 seconds
[2023-09-25T17:26:06.816+0700] {processor.py:157} INFO - Started process (PID=5490) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:26:06.818+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:26:06.822+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:26:06.821+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:26:07.030+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:26:07.047+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:26:07.047+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:26:07.060+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:26:07.060+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:26:07.071+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.260 seconds
[2023-09-25T17:26:37.179+0700] {processor.py:157} INFO - Started process (PID=5547) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:26:37.180+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:26:37.183+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:26:37.182+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:26:37.372+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:26:37.388+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:26:37.388+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:26:37.400+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:26:37.400+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:26:37.410+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.236 seconds
[2023-09-25T17:27:07.673+0700] {processor.py:157} INFO - Started process (PID=5603) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:27:07.675+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:27:07.679+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:27:07.678+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:27:07.867+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:27:07.883+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:27:07.883+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:27:07.895+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:27:07.895+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:27:07.907+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T17:27:38.155+0700] {processor.py:157} INFO - Started process (PID=5659) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:27:38.157+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:27:38.160+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:27:38.160+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:27:38.351+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:27:38.366+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:27:38.366+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:27:38.379+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:27:38.379+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:27:38.389+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.239 seconds
[2023-09-25T17:28:08.586+0700] {processor.py:157} INFO - Started process (PID=5715) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:28:08.588+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:28:08.590+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:28:08.590+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:28:08.795+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:28:08.812+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:28:08.812+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:28:08.826+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:28:08.826+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:28:08.837+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
[2023-09-25T17:28:39.203+0700] {processor.py:157} INFO - Started process (PID=5771) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:28:39.204+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:28:39.206+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:28:39.206+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:28:39.405+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:28:39.423+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:28:39.422+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:28:39.438+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:28:39.437+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:28:39.450+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.250 seconds
[2023-09-25T17:29:09.668+0700] {processor.py:157} INFO - Started process (PID=5827) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:29:09.669+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:29:09.672+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:29:09.671+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:29:09.858+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:29:09.874+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:29:09.874+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:29:09.888+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:29:09.888+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:29:09.899+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.234 seconds
[2023-09-25T17:29:40.062+0700] {processor.py:157} INFO - Started process (PID=5884) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:29:40.063+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:29:40.065+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:29:40.065+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:29:40.258+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:29:40.274+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:29:40.274+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:29:40.288+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:29:40.288+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:29:40.298+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.239 seconds
[2023-09-25T17:30:10.359+0700] {processor.py:157} INFO - Started process (PID=5940) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:30:10.361+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:30:10.364+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:30:10.363+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:30:10.553+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:30:10.568+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:30:10.568+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:30:10.581+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:30:10.581+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:30:10.591+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T17:30:40.768+0700] {processor.py:157} INFO - Started process (PID=5996) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:30:40.770+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:30:40.773+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:30:40.773+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:30:40.959+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:30:40.973+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:30:40.973+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:30:40.985+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:30:40.985+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:30:40.994+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.230 seconds
[2023-09-25T17:31:11.209+0700] {processor.py:157} INFO - Started process (PID=6052) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:31:11.211+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:31:11.214+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:31:11.213+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:31:11.404+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:31:11.419+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:31:11.418+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:31:11.430+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:31:11.430+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:31:11.441+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.237 seconds
[2023-09-25T17:31:41.627+0700] {processor.py:157} INFO - Started process (PID=6108) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:31:41.629+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:31:41.632+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:31:41.631+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:31:41.818+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:31:41.832+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:31:41.832+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:31:41.844+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:31:41.844+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:31:41.854+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.232 seconds
[2023-09-25T17:32:12.076+0700] {processor.py:157} INFO - Started process (PID=6164) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:32:12.078+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:32:12.081+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:32:12.081+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:32:12.275+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:32:12.290+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:32:12.290+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:32:12.302+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:32:12.302+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:32:12.311+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.240 seconds
[2023-09-25T17:32:42.446+0700] {processor.py:157} INFO - Started process (PID=6220) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:32:42.447+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:32:42.449+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:32:42.448+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:32:42.627+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:32:42.643+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:32:42.643+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:32:42.655+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:32:42.655+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:32:42.665+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.222 seconds
[2023-09-25T17:33:12.844+0700] {processor.py:157} INFO - Started process (PID=6276) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:33:12.846+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:33:12.849+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:33:12.849+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:33:13.038+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:33:13.054+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:33:13.054+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:33:13.067+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:33:13.067+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:33:13.077+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T17:33:43.256+0700] {processor.py:157} INFO - Started process (PID=6332) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:33:43.258+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:33:43.261+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:33:43.260+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:33:43.457+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:33:43.472+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:33:43.472+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:33:43.486+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:33:43.485+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:33:43.496+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.245 seconds
[2023-09-25T17:34:13.628+0700] {processor.py:157} INFO - Started process (PID=6388) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:34:13.629+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:34:13.631+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:34:13.631+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:34:13.819+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:34:13.835+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:34:13.835+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:34:13.847+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:34:13.847+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:34:13.857+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.232 seconds
[2023-09-25T17:34:43.959+0700] {processor.py:157} INFO - Started process (PID=6444) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:34:43.960+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:34:43.961+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:34:43.961+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:34:44.151+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:34:44.167+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:34:44.167+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:34:44.180+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:34:44.180+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:34:44.191+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.235 seconds
[2023-09-25T17:35:14.215+0700] {processor.py:157} INFO - Started process (PID=6499) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:35:14.216+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:35:14.218+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:35:14.217+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:35:14.403+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:35:14.419+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:35:14.419+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:35:14.433+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:35:14.433+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:35:14.444+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.232 seconds
[2023-09-25T17:35:44.483+0700] {processor.py:157} INFO - Started process (PID=6555) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:35:44.485+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:35:44.487+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:35:44.486+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:35:44.691+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:35:44.709+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:35:44.708+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:35:44.723+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:35:44.723+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:35:44.736+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.256 seconds
[2023-09-25T17:36:14.869+0700] {processor.py:157} INFO - Started process (PID=6611) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:36:14.870+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:36:14.872+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:36:14.872+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:36:15.061+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:36:15.076+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:36:15.076+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:36:15.088+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:36:15.088+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:36:15.099+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.233 seconds
[2023-09-25T17:36:45.378+0700] {processor.py:157} INFO - Started process (PID=6666) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:36:45.380+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:36:45.383+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:36:45.383+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:36:45.578+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:36:45.593+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:36:45.593+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:36:45.607+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:36:45.606+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:36:45.617+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T17:37:15.961+0700] {processor.py:157} INFO - Started process (PID=6727) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:37:15.963+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:37:15.966+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:37:15.965+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:37:16.156+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:37:16.171+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:37:16.171+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:37:16.183+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:37:16.183+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:37:16.193+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.236 seconds
[2023-09-25T17:37:46.435+0700] {processor.py:157} INFO - Started process (PID=6783) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:37:46.437+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:37:46.441+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:37:46.440+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:37:46.640+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:37:46.656+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:37:46.656+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:37:46.669+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:37:46.669+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:37:46.684+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.254 seconds
[2023-09-25T17:38:17.220+0700] {processor.py:157} INFO - Started process (PID=6839) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:38:17.222+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:38:17.225+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:38:17.224+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:38:17.413+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:38:17.428+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:38:17.428+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:38:17.440+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:38:17.440+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:38:17.451+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.235 seconds
[2023-09-25T17:38:47.690+0700] {processor.py:157} INFO - Started process (PID=6895) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:38:47.692+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:38:47.695+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:38:47.695+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:38:47.882+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:38:47.896+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:38:47.896+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:38:47.908+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:38:47.908+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:38:47.918+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.233 seconds
[2023-09-25T17:39:18.115+0700] {processor.py:157} INFO - Started process (PID=6951) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:39:18.117+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T17:39:18.120+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:39:18.120+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:39:18.306+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T17:39:18.321+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:39:18.321+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T17:39:18.333+0700] {logging_mixin.py:151} INFO - [2023-09-25T17:39:18.333+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T17:39:18.343+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.233 seconds
[2023-09-25T22:11:36.983+0700] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:11:36.988+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T22:11:36.991+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:11:36.990+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:11:37.649+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:11:37.674+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:11:37.674+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T22:11:37.689+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:11:37.689+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T22:11:37.707+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.733 seconds
[2023-09-25T22:12:08.543+0700] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:12:08.544+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T22:12:08.547+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:12:08.546+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:12:08.741+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:12:08.756+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:12:08.756+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T22:12:08.770+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:12:08.770+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T22:12:08.780+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.241 seconds
[2023-09-25T22:12:38.961+0700] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:12:38.962+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T22:12:38.965+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:12:38.964+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:12:39.155+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:12:39.170+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:12:39.170+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T22:12:39.184+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:12:39.184+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T22:12:39.196+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T22:13:09.239+0700] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:13:09.240+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T22:13:09.242+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:13:09.242+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:13:09.433+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:13:09.451+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:13:09.451+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T22:13:09.466+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:13:09.466+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T22:13:09.478+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.241 seconds
[2023-09-25T22:13:39.518+0700] {processor.py:157} INFO - Started process (PID=257) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:13:39.519+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T22:13:39.521+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:13:39.521+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:13:39.700+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:13:39.715+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:13:39.715+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T22:13:39.729+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:13:39.729+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T22:13:39.739+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.224 seconds
[2023-09-25T22:14:09.808+0700] {processor.py:157} INFO - Started process (PID=311) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:14:09.810+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T22:14:09.812+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:14:09.811+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:14:10.005+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T22:14:10.020+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:14:10.020+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T22:14:10.033+0700] {logging_mixin.py:151} INFO - [2023-09-25T22:14:10.033+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T22:14:10.042+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.238 seconds
[2023-09-25T23:26:19.131+0700] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:26:19.135+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:26:19.138+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:26:19.138+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:26:19.743+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:26:19.774+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:26:19.774+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:26:19.794+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:26:19.794+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:26:19.817+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.689 seconds
[2023-09-25T23:26:49.994+0700] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:26:49.995+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:26:49.998+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:26:49.997+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:26:50.203+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:26:50.219+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:26:50.219+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:26:50.232+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:26:50.232+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:26:50.242+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.255 seconds
[2023-09-25T23:27:20.378+0700] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:27:20.379+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:27:20.381+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:27:20.381+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:27:20.581+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:27:20.596+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:27:20.596+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:27:20.611+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:27:20.611+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:27:20.621+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T23:27:50.676+0700] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:27:50.684+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:27:50.686+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:27:50.686+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:27:50.889+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:27:50.906+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:27:50.905+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:27:50.918+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:27:50.918+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:27:50.930+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.257 seconds
[2023-09-25T23:28:21.914+0700] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:28:21.916+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:28:21.918+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:28:21.918+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:28:22.115+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:28:22.131+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:28:22.131+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:28:22.144+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:28:22.144+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:28:22.155+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.244 seconds
[2023-09-25T23:28:52.194+0700] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:28:52.195+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:28:52.197+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:28:52.197+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:28:52.453+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:28:52.470+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:28:52.469+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:28:52.486+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:28:52.485+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:28:52.498+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.307 seconds
[2023-09-25T23:29:23.138+0700] {processor.py:157} INFO - Started process (PID=370) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:29:23.140+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:29:23.143+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:29:23.142+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:29:23.338+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:29:23.354+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:29:23.354+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:29:23.368+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:29:23.368+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:29:23.379+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.246 seconds
[2023-09-25T23:29:53.620+0700] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:29:53.622+0700] {processor.py:829} INFO - Processing file /opt/airflow/dags/crawlInvest.py for tasks to queue
[2023-09-25T23:29:53.624+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:29:53.624+0700] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:29:53.828+0700] {processor.py:839} INFO - DAG(s) dict_keys(['crawl_dag_v01']) retrieved from /opt/airflow/dags/crawlInvest.py
[2023-09-25T23:29:53.844+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:29:53.843+0700] {dag.py:2915} INFO - Sync 1 DAGs
[2023-09-25T23:29:53.858+0700] {logging_mixin.py:151} INFO - [2023-09-25T23:29:53.858+0700] {dag.py:3696} INFO - Setting next_dagrun for crawl_dag_v01 to None, run_after=None
[2023-09-25T23:29:53.868+0700] {processor.py:179} INFO - Processing /opt/airflow/dags/crawlInvest.py took 0.253 seconds
